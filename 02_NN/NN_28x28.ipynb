{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d3c7d6-779a-437a-84b2-55cfdf0d28f9",
   "metadata": {},
   "source": [
    "# Neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d1ecb-511f-490b-b0f8-58fdc2c15d97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One-Hot-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7faeb5b-b3cc-4319-8548-a50cbc5131ee",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load numpy array from npy file\n",
    "\n",
    "# load array\n",
    "\n",
    "X_train=load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32) * 1.0/255.0 # normalisieren\n",
    "y_train=load('../01_Dataset/dataset_28x28/y_train.npy')\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32) * 1.0/255.0  # normalisieren\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(y_train))\n",
    "print(X_test.shape)\n",
    "print(len(y_test))\n",
    "\n",
    "\n",
    "oh = OneHotEncoder()\n",
    "y_train_oh = oh.fit_transform(y_train.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9abbea4-7415-4a8f-af21-04e3658d3725",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90016671-e95c-48c6-ac36-68e8c5eba084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label check\n",
    "i=5\n",
    "print(y_train[i])\n",
    "print(y_train_oh[i])\n",
    "plt.imshow(X_train[i],cmap='gray')\n",
    "plt.show\n",
    "# 0: innensechskant\n",
    "# 1: philips\n",
    "# 2: pozidriv\n",
    "# 3: sechskant\n",
    "# 4: torx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b7e5c3-ee69-44ff-af6d-27f3119d32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(2753, 784)\n",
      "[3 0 1 ... 1 0 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32).reshape(-1, 784)#reshape hier wegen label test\n",
    "X_test  = X_test.astype(np.float32).reshape(-1, 784)#\n",
    "print(X_train)\n",
    "print(X_test.shape)\n",
    "y_test = y_test.astype(np.int)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4dd99-f11d-49ad-af8e-bb08c361d324",
   "metadata": {
    "tags": [
     "hide-input",
     "scroll-output"
    ]
   },
   "source": [
    "```python\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    for j in range(0, len(X_train), 100):\n",
    "        model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    print(np.mean(y_test_pred == y_test))\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee28da-1f15-4af7-9be9-f5b8574ed567",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mehrere Ausgänge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c1e41c-3159-476d-9f75-bff398f0d130",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32).reshape(-1, 784)*1.0/255.0\n",
    "y_train = load('../01_Dataset/dataset_28x28/y_train.npy').astype(np.int32)\n",
    "\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32).reshape(-1, 784)*1.0/255.0\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy').astype(np.int32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d4fa8-e7d3-4c48-a187-8b8120c3b181",
   "metadata": {
    "tags": [
     "hide-cell",
     "scroll-output"
    ]
   },
   "source": [
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(5, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678d636-36c5-4a65-9ef0-ccfa5a358253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f447d966-2104-47a3-b768-d4122409a0e8",
   "metadata": {},
   "source": [
    "```python\n",
    "model.evaluate(X_test.reshape(-1, 784), y_test)\n",
    "model.predict(X_test.reshape(-1, 784))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(y_test[1])\n",
    "\n",
    "plt.imshow(X_test[1].reshape(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "np.argmax(pred[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aeb13b-c957-4616-8e2c-56ad32f2a3f9",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c03636-871c-4115-b9a3-7c895d03b01b",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "ytrue = pd.Series(np.argmax(y_test, axis= 1), name = 'ytrue')\n",
    "ypred = pd.Series(np.argmax(pred, axis= 1), name = 'pred')\n",
    "pd.crosstab(ytrue, ypred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1493c26-bcf7-459d-97c8-749051c21e9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lernkurve plotten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4eb18b-0925-4da0-86a7-2dc8a8f51167",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "```python\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "limits = [100, 1000, 3000, 9000, 10500]\n",
    "test_accs = []\n",
    "train_accs = []\n",
    "for limit in limits:\n",
    "    model = NeuralNetwork(0.25)\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        for j in range(0, limit, 100):\n",
    "           model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    test_acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    y_train_pred = model.predict(X_train / 255.)\n",
    "    y_train_pred = np.argmax(y_train_pred, axis=0)\n",
    "    train_acc = np.mean(y_train_pred == y_train)\n",
    "\n",
    "    test_accs.append(test_acc)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(limits, train_accs, label=\"Training\")\n",
    "plt.plot(limits, test_accs, label=\"Test\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659348c4-222c-48a9-ac03-1f679fe47c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b43b0a-a629-4314-9afe-824d4892292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13167647-efc2-4aa4-89b6-8a39874c8ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lernrate plotten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa381d8-3d22-460e-8da2-0b400446274e",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "```python\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "epochs = []\n",
    "costs = []\n",
    "accs = []\n",
    "\n",
    "for i in range(0, 50):\n",
    "    for j in range(0, 10500, 100):\n",
    "        model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "    cost = model.cost(model.predict(X_train), y_train_oh)\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    epochs.append(i + 1)\n",
    "    costs.append(cost)\n",
    "    accs.append(acc)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(epochs, costs, label=\"Kosten\")\n",
    "plt.plot(epochs, accs, label=\"Genauigkeit\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d39364-d08d-416e-a7b0-decab5a28071",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d12db-fe89-4e9b-b113-c288b426a7ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Netzwerkgröße"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be921df-9def-4203-a3d3-bf248967079d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "```python\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1, hidden_size = 100):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(hidden_size, 784)\n",
    "        self.w1 = np.random.randn(5, hidden_size)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "for hidden_size in [500, 600, 700, 800]:\n",
    "\n",
    "    model = NeuralNetwork(0.3, hidden_size)\n",
    "\n",
    "    for i in range(0, 25):\n",
    "        for j in range(0, 10500, 100):\n",
    "            model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "        # cost = model.cost(model.predict(X_train), y_train_oh)\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    print(str(hidden_size) + \": \" + str(acc))\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2fb270-2b95-4421-98a5-12b621ac09ed",
   "metadata": {},
   "source": [
    "```python\n",
    "count=0\n",
    "for i in range(0, len(X_test)):\n",
    "    if y_test_pred[i] == 2 and y_test[i] ==1:\n",
    "        count += 1\n",
    "        plt.imshow(X_test[i].reshape(28, 28))\n",
    "        plt.show()\n",
    "        print(count)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd596e-ce27-4d2e-ac37-09721ae69f32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
