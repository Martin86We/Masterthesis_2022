{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c13b31-e6cd-4dac-af17-4a54a123d45b",
   "metadata": {},
   "source": [
    "# Datensatz 2 (Schrauben)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7487b-fac7-4321-9b78-636886d59537",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bilder aus Video extrahieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1b582-09b8-4d8e-9caa-9e8fe391127e",
   "metadata": {},
   "source": [
    "Die folgenden Videos wurden unter möglichst gleichen Bedingungen aufgenommen, so dass die Trainingsbilder sich nur durch die Schrauben unterscheiden.\n",
    "\n",
    "\n",
    "Hier noch Videos anzeigen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5a98a-20a1-40f9-800c-790b246aa8b5",
   "metadata": {},
   "source": [
    "````\n",
    "# OpenCV importieren:\n",
    "import cv2\n",
    "\n",
    "# path = 'relativer Speicherpfad / Dateiname':\n",
    "path = 'frames_from_video/torx'\n",
    "\n",
    "\n",
    "# Video laden:\n",
    "cap = cv2.VideoCapture('video/torx.MOV')\n",
    "i = 0\n",
    "\n",
    "\n",
    "# Prüfen ob ein Video geladen wurde:\n",
    "if cap.isOpened() == False:\n",
    "    print('ERROR: Datei nicht gefunden')\n",
    "   \n",
    "    \n",
    "# Die Frames des Videos lesen:      \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "     \n",
    "    # sobald keine Frames mehr gelesen werden können (ret==False) wird abgebrochen:\n",
    "    if ret == False:\n",
    "        break\n",
    "     \n",
    "    # Die Frames speichern\n",
    "    cv2.imwrite(path+str(_i)+'.jpg', frame)\n",
    "    i += 1\n",
    " \n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2caf115-8ccd-4584-b4d7-5d782fffceca",
   "metadata": {},
   "source": [
    "Schneiden und skalieren Sie das Bild auf die richtige Größe und normalisieren Sie die Farben. Alle in Keras enthaltenen vortrainierten Netze erfordern, dass die Eingabedaten quadratisch und in einer bestimmten Größe vorliegen. Außerdem erwarten sie, dass die Farbkanäle normalisiert sind. Die Normalisierung der Bilder für das Training erleichtert dem Netzwerk, sich auf die wichtigen Dinge zu konzentrieren und sich dabei nicht »ablenken« zu lassen.\n",
    "Osinga, Douwe. Deep Learning Kochbuch : Praxisrezepte für einen schnellen Einstieg, o'Reilly, 2019. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/htwg-konstanz/detail.action?docID=5704334.\n",
    "Created from htwg-konstanz on 2022-02-16 00:04:42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da770f7c-3f18-4c90-8c04-4027488c029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importieren der Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cdc38-2248-4e4e-a809-c2a682340932",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bildausschnitt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f5b4c-3ec4-4ce3-a892-81cda37f28d8",
   "metadata": {},
   "source": [
    "Wir können PIL/Pillow verwenden, um ein Bild zu laden und die Bildmitte auszuschneiden:\n",
    "Osinga, Douwe. Deep Learning Kochbuch : Praxisrezepte für einen schnellen Einstieg, o'Reilly, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021e2ad-f9c5-4b90-ac7a-214e82d2fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db098529-adea-443b-bd37-5e17e52b6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('frames_from_video/pozidriv0.jpg')\n",
    "plt.imshow(img)\n",
    "w, h = img.size \n",
    "s = min(w, h) \n",
    "y = (h - s) // 2 \n",
    "x = (w - s) // 2 \n",
    "img_crop = img.crop((x, y, s, s))\n",
    "plt.imshow(img_crop)\n",
    "print(\"w = \" + str(w))\n",
    "print(\"h = \" + str(h))\n",
    "print(\"s = \" + str(s))\n",
    "print(\"y = \" + str(y))\n",
    "print(\"x = \" + str(x))\n",
    "# Osinga, Douwe. Deep Learning Kochbuch : Praxisrezepte für einen schnellen Einstieg, o'Reilly, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855808b-fd39-47e9-9b7d-2178cd9f05ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bild verkleinern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba713e0f-2edd-41fb-98c2-1f98d4385117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('frames_from_video/pozidriv0.jpg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "print('Original Dimensions : ',img.shape)\n",
    "\n",
    "scale_percent = 50 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "#resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "print('Resized Dimensions : ',resized.shape)\n",
    "\n",
    "cv2.imshow(\"Resized image\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887970d1-a90f-450d-b086-cb3cd38a77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "filelist = glob.glob(\"screw_img/**/*\")\n",
    "X_raw = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "print(X_raw.shape)\n",
    "print(len(filelist))\n",
    "\n",
    "# Array erweitern - hier nicht nötig\n",
    "#X_raw = X_raw.reshape(X_raw.shape + (1,))\n",
    "#print(X_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83667f-db43-458d-b79e-62b805db4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = glob.glob(\"screw_img/**/*\")\n",
    "X_gray = np.array([np.array(Image.open(fname).convert('L')) for fname in filelist])\n",
    "print(X_gray.shape)\n",
    "print(len(filelist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264445df-dd2b-4678-9e48-95e5f3255d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array erweitern \n",
    "#X_gray = X_gray.reshape(X_gray.shape + (1,))\n",
    "print(X_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a86db0-d48d-4164-9053-c06418254ed4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Auto Object Cropping (YOLOv4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde98d6-d491-4260-ad0d-b5f051cf9df2",
   "metadata": {},
   "source": [
    "Wie das YOLO Netzwerk dafür genutzt werden kann Objekte auf Bildern auszuschneiden: [\"Video: Crop and Save\"](https://www.youtube.com/watch?v=P7r0hIP2GQ4)  \n",
    "Den Code: [Github](https://github.com/theAIGuysCode/yolov4-custom-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62677f08-ceb3-4832-bf47-94c333895192",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Beispiel Bilder anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e665d-8819-4d30-afe6-a3a98193fa32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8135b-7f59-4acb-8bf9-3918ea1b3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "pozidriv = mpimg.imread('screw_img_224x224/pozidriv/pozi (1288).jpg')\n",
    "kreuzschlitz = mpimg.imread('screw_img_224x224/kreuzschlitz/kreuzschlitz (1592).jpg')\n",
    "philips = mpimg.imread('screw_img_224x224/philips/philips (1148).jpg')\n",
    "innensechskant = mpimg.imread('screw_img_224x224/innensechskant/innensechskant (1).jpg')\n",
    "sechskant = mpimg.imread('screw_img_224x224/sechskant/sechskant (1334).jpg')\n",
    "torx = mpimg.imread('screw_img_224x224/torx/torx (1178).jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad04ed-6f1d-4329-8b4b-1c63ce61a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(1, 6, 1)\n",
    "plt.title('Pozidriv')\n",
    "plt.imshow(pozidriv, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 6, 2)\n",
    "plt.title('Philips')\n",
    "plt.imshow(philips, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 6, 4)\n",
    "plt.title('Innensechskant')\n",
    "plt.imshow(innensechskant, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 6, 5)\n",
    "plt.title('Torx')\n",
    "plt.imshow(torx, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 6, 6)\n",
    "plt.title('Sechskant')\n",
    "plt.imshow(sechskant, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 6, 3)\n",
    "plt.title('Kreuzschlitz')\n",
    "plt.imshow(kreuzschlitz, cmap='gray')\n",
    "\n",
    "plt.suptitle('Schrauben Klassen', fontsize=22)\n",
    "#plt.subplots_adjust(left=0.3, wspace=0.2, top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b9938-558d-4322-b04a-d393062e26f9",
   "metadata": {},
   "source": [
    "Aus diesen 5 Schraubenarten wird nun ein Datensatz mit Labels erstellt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd5f7d-e3bc-4581-9929-f8afd6c0ed06",
   "metadata": {},
   "source": [
    "In diesem Abschnitt soll ein Datensatz aus \"echten\" Fotos erstellt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db0f80-e7e4-413d-b4e7-8b48bdefeedc",
   "metadata": {},
   "source": [
    "Wie viele Trainingsdaten benötigt das Netz? Sind [genug Trainingsdaten](https://towardsdatascience.com/how-do-you-know-you-have-enough-training-data-ad9b1fd679ee) vorhanden?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def831b2-ec17-457b-9fa4-79c54293cc7f",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Es stellt sich die Frage wie detailreich die Schraubenbilder sein müssen um eine gute Erkennung zu ermöglichen?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b360d5-0d3c-44d6-bbe2-0723ceb86d95",
   "metadata": {},
   "source": [
    "Um kostengünstig und schnell eine vielzahl an Trainingsbildern von Schrauben zu erzeugen, bieten sich Videoaufnahmen der Schrauben an. Die Videoaufnahmen lassen sich in einzelne Bildern zerlegen und somit ein Datensatz erzeugen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7929cd5-06cc-432e-90ed-047f49682717",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Alle Bilder in einem Ordner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393fba8d-fd53-4326-8103-47b116cfa143",
   "metadata": {},
   "source": [
    "Die Labelliste muss dem Image-Array korrekt zugeordnet werden. Dafür müssen Bilder und zugehörige Labels in gleicher Reihenfolge abgespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10252831-dec4-43d8-81ab-35ba67d139c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab58c6-9e44-4fc2-afab-741a202744ee",
   "metadata": {},
   "source": [
    "````\n",
    "# Liste mit Dateipfad anlegen\n",
    "filelist = glob.glob(\"frames_from_video/*\")\n",
    "\n",
    "# Bilder in ein 3 Dimensionales Numpy Array speichern\n",
    "X = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "\n",
    "# Array erweitern auf 4D-Array (n,n,n,1)\n",
    "X = X.reshape(X.shape + (1,))\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879e687-eccd-4c1e-bd54-a6233233c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262e405-53fc-489d-b026-d623ad033dba",
   "metadata": {},
   "source": [
    "Das Bilder Array **X** wurde nun erstellt. Nun müssen noch die zugehörigen *Labels* erzeugt werden.\n",
    "\n",
    "Folgende Ausgangssituationen sollen untersucht werden:\n",
    "  1. Alle Bilder liegen in einem Ordner und jedes Bild besitzt Klassenname und Nummerierung im Dateinamen\n",
    "  2. Jede Klasse in einem eigenen Ordner, Dateinamen benötigen lediglich eine fortlaufende Nummerierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06165bb7-595f-4c62-8f2c-5cab6cc5efa3",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "path = \"dataset_from_video\"\n",
    "categories = [] \n",
    "\n",
    "for img in os.listdir(path):  # hole mir die Bezeichnung aus dem Dateinamen des Bildes, teile den Dateinamen am Leerzeichen (\" \") und nutze den Klassennamen als Label\n",
    "    if img.startswith(\"innensechskant\"):\n",
    "        category_, rand_str = img.split(' ') # teile auf in \"innensechskant\" und \"28x28_gray\"\n",
    "        categories.append(category_)# erweitere die Labelliste mit \"innensechskant\"\n",
    "            \n",
    "for img in os.listdir(path):  # iterate over each image per Categorie\n",
    "    if img.startswith(\"philips\"):\n",
    "        category_, rand_str = img.split(' ')\n",
    "        categories.append(category_)\n",
    "            \n",
    "for img in os.listdir(path):  # iterate over each image per Categorie\n",
    "    if img.startswith(\"pozidriv\"):\n",
    "        category_, rand_str = img.split(' ')\n",
    "        categories.append(category_)\n",
    "            \n",
    "for img in os.listdir(path):  # iterate over each image per Categorie\n",
    "    if img.startswith(\"sechskant\"):\n",
    "        category_, rand_str = img.split(' ')\n",
    "        categories.append(category_)\n",
    "            \n",
    "for img in os.listdir(path):  # iterate over each image per Categorie\n",
    "    if img.startswith(\"torx\"):\n",
    "        category_, rand_str = img.split(' ')\n",
    "        categories.append(category_)\n",
    "        \n",
    "y=categories\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe88792-a06e-4b92-9b1c-d112316c87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Test\n",
    "i=3\n",
    "print(y[i])\n",
    "plt.imshow(X[i],cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79421453-9a60-4ba5-83d7-2601fd17fc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae063a9-c193-4819-bb9c-689bf789d883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb4d39-930f-4492-a87c-6ac44f9ae412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2c6a8de-5416-459f-9a7a-2dd1c0f26011",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bilderklassen in separatem Ordner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dde680-04b3-4073-bfcf-0647fba0e768",
   "metadata": {},
   "source": [
    "Die folgende Ordnerstruktur liegt vor:\n",
    "\n",
    "main_directory/  \n",
    "...category_a/  \n",
    "......a_image_1.jpg  \n",
    "......a_image_2.jpg  \n",
    "...category_b/  \n",
    "......b_image_1.jpg  \n",
    "......b_image_2.jpg  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e211276-4aa8-47d1-984b-b652cf74b97a",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = 'C:/Users/Martin/OneDrive/Masterthesis_2022/01_Dataset/ImageDataset_Classes'\n",
    "\n",
    "CATEGORIES = ['innensechskant', 'philips', 'pozidriv', 'sechskant', 'torx']\n",
    "\n",
    "for category in CATEGORIES:  # do dogs and cats\n",
    "    path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break  \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439613c5-64ea-4e7f-9eec-9da10b3ad1ce",
   "metadata": {},
   "source": [
    "training_data = []\n",
    "\n",
    "IMG_SIZE=224\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9fc59-cd31-4228-a10f-2d2eaf4bd8e6",
   "metadata": {},
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c7fbe-540c-4b8c-b1a9-3e7a549f9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fc2fe-b8d8-4364-8716-cb8d5b8b2fe6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datensatz aufteilen in Test- und Trainingsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0178c-a4cf-4e63-a928-af6d51e80418",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35647a-c073-4a11-b132-0b2a3f7f994e",
   "metadata": {},
   "source": [
    "```\n",
    "from numpy import save, load\n",
    "# define data\n",
    "#data = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "# save to npy file\n",
    "save('Dataset_224x224/X_train.npy', X_train)\n",
    "save('Dataset_224x224/y_train.npy', y_train)\n",
    "save('Dataset_224x224/X_test.npy', X_test)\n",
    "save('Dataset_224x224/y_test.npy', y_test)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61c01b-1375-4a40-aeea-f91799c0c62b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datensatz mit Keras erzeugen und erweitern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b9ece-9f24-4f6e-8ef1-f9a4a77414f1",
   "metadata": {},
   "source": [
    "Mit dem ImageDataGenerator aus dem Keras Paket *Image data preprocessing*, kann ein Datensatz erstellt werden.\n",
    "Der Image Data Generator bietet eine Reihe nützlicher Funktionen um einen Datensatz aus Bildern zu erstellen und zu erweitern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee5ae6-2040-4ea0-b153-e1c4a7d3c053",
   "metadata": {},
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b5178-d5a4-4cd3-aefe-0c8ce37b48e8",
   "metadata": {},
   "source": [
    "```\n",
    "# Create a dataset.\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "  'screw_img', batch_size=100, image_size=(224, 224))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For demonstration, iterate over the batches yielded by the dataset.\n",
    "for data, labels in dataset:\n",
    "    print(data.shape)  # (64, 200, 200, 3)\n",
    "    print(data.dtype)  # float32\n",
    "    print(labels.shape)  # (64,)\n",
    "    print(labels.dtype)  # int32\n",
    "    break\n",
    "    \n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81714c8e-086e-4191-aaf2-d90a4b8aad00",
   "metadata": {},
   "source": [
    "```\n",
    "X_ = []\n",
    "y_ = []\n",
    "\n",
    "for features,label in dataset:\n",
    "    X_.append(features)\n",
    "    y_.append(label)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f938dfe-afcb-4551-ac41-4dc989361524",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fed77e-2397-4a93-9dc2-15ac9f69a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394aa26-75c2-4b4e-a760-c26e581e254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d92cee-9c87-4c55-8e08-be5d454f60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = X.class_names\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1240f6-6345-436c-8958-b44b50d711bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generator ausprobieren und konfigurieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc4f65-9a3f-4e96-b54e-9e6af18dfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator config:\n",
    "gen = ImageDataGenerator (\n",
    "    #width_shift_range=0,\n",
    "    #height_shift_range=0,\n",
    "    #rotation_range=0,\n",
    "    #shear_range=0.01,\n",
    "    #zoom_range=0.2,\n",
    "    #fill_mode='constant',cval=255 # beste fill mode bei einfarbigen Hintergrund\n",
    ")\n",
    "# generate one image:\n",
    "for batch in gen.flow(\n",
    "    X_raw,\n",
    "    shuffle=False,\n",
    "):\n",
    "    #print(batch.shape)\n",
    "    plt.imshow(batch[0]/255)\n",
    "    plt.show\n",
    "    break\n",
    "    \n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad720a-0a37-4813-b954-281abe554114",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant',\n",
    "    cval=255,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=1.0/255.0,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "itr = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=None,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    save_to_dir='Dataset_vid',\n",
    "    #save_prefix=\"\",\n",
    "    save_format=\"png\",\n",
    "    follow_links=False,\n",
    "    subset=None,\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "    \n",
    "    \n",
    "#target_size=(img_width, img_height),\n",
    "#batch_size=10,\n",
    "#class_mode='categorical')\n",
    "\n",
    "i=0\n",
    "\n",
    "for i in range(0,3):\n",
    "    X, y = itr.next()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1140c-3c24-45e6-923c-12ffe1b2e823",
   "metadata": {},
   "source": [
    "```\n",
    "from numpy import save, load\n",
    "# define data\n",
    "#data = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "# save to npy file\n",
    "save('Dataset_vid/X_train.npy', X_train)\n",
    "save('Dataset_vid/y_train.npy', y_train)\n",
    "save('Dataset_vid/X_test.npy', X_test)\n",
    "save('Dataset_vid/y_test.npy', y_test)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
