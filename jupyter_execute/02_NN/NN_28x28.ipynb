{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d3c7d6-779a-437a-84b2-55cfdf0d28f9",
   "metadata": {},
   "source": [
    "# Neuronales Netz (28x28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d1ecb-511f-490b-b0f8-58fdc2c15d97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## One-Hot-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7faeb5b-b3cc-4319-8548-a50cbc5131ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from scipy.special import expit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e846e4ff-7980-497f-9722-5ca3326442b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7394, 28, 28, 1)\n",
      "7394\n",
      "(3169, 28, 28, 1)\n",
      "3169\n"
     ]
    }
   ],
   "source": [
    "# load numpy array from npy file\n",
    "\n",
    "# load array\n",
    "\n",
    "X_train=load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32) * 1.0/255.0 # normalisieren\n",
    "y_train=load('../01_Dataset/dataset_28x28/y_train.npy')\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32) * 1.0/255.0  # normalisieren\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(len(y_train))\n",
    "print(X_test.shape)\n",
    "print(len(y_test))\n",
    "\n",
    "\n",
    "oh = OneHotEncoder()\n",
    "y_train_oh = oh.fit_transform(y_train.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcbbec1d-bb5f-4243-bd98-e308307a702e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7394, 28, 28, 1)\n",
      "(3169, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5365d36-d358-4551-a5cc-3a0149780202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90016671-e95c-48c6-ac36-68e8c5eba084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "C:\\Users\\Martin\\Onedrive\\Masterthesis_2022\\_build\\jupyter_execute\\02_NN\\NN_28x28_6_2.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label check\n",
    "i=7\n",
    "print(y_train[i])\n",
    "print(y_train_oh[i])\n",
    "plt.imshow(X_train[i],cmap='gray')\n",
    "plt.show\n",
    "# 0: innensechskant\n",
    "# 1: philips\n",
    "# 2: pozidriv\n",
    "# 3: sechskant\n",
    "# 4: torx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b7e5c3-ee69-44ff-af6d-27f3119d32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "(3169, 784)\n",
      "[4 0 4 ... 3 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float32).reshape(-1, 784)#reshape hier wegen label test\n",
    "X_test  = X_test.astype(np.float32).reshape(-1, 784)#\n",
    "print(X_train)\n",
    "print(X_test.shape)\n",
    "y_test = y_test.astype(np.int)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf8041e5-5b8c-4193-b3f7-2dd4567eda4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124013884506153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31271694540864625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31271694540864625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31271694540864625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31271694540864625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2172/3809888729.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m                 \u001b[1;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    545\u001b[0m                 )\n\u001b[0;32m    546\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "for i in range(0, 500):\n",
    "    for j in range(0, len(X_train), 100):\n",
    "        model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    print(np.mean(y_test_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2e879e-fc9e-463e-b068-026a7424b76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4411764705882353"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee28da-1f15-4af7-9be9-f5b8574ed567",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mehrere Ausgänge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c1e41c-3159-476d-9f75-bff398f0d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from numpy import load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32).reshape(-1, 784)*1.0/255.0\n",
    "y_train = load('../01_Dataset/dataset_28x28/y_train.npy').astype(np.int32)\n",
    "\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32).reshape(-1, 784)*1.0/255.0\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy').astype(np.int32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdc4684-03b8-47e9-87f2-3b27fbd26d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7723e7b-abbb-4a81-a31c-ffdda7a6d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation=\"sigmoid\", input_shape=(784,)))\n",
    "model.add(Dense(5, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea312a7e-6706-445b-991e-a475abda2777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.8206\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8217\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8224\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8263\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8265\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8279\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8290\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8269\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.8304\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8317\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8309\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8323\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8328\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8359\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8369\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8369\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8384\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8397\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8389\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8419\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8408\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8432\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8424\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8424\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8441\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8427\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8441\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8446\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8462\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8466\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8466\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8477\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8490\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8495\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8482\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8503\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8504\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8488\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3574 - accuracy: 0.8506\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8507\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8515\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8510\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8506\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8517\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8528\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8540\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8521\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8551\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8540\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8515\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8540\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8542\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8550\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8570\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8586\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8566\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8577\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8539\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8583\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8586\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8566\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8591\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8584\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8572\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8594\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8561\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8592\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8597\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8597\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8597\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8600\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8588\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8591\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3147 - accuracy: 0.8596\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8578\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8602\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8594\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3115 - accuracy: 0.8597\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8611\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8599\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.8614\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.8630\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8610\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8599\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.8619\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.8596\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8627\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8637\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3037 - accuracy: 0.8624\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8627\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8605\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8624\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8622\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8635\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8613\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8618\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8643\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23939ddb348>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678d636-36c5-4a65-9ef0-ccfa5a358253",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test.reshape(-1, 784), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bcf274-5871-468c-a53f-b9e08ecd6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test.reshape(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838d57d-e600-42d1-b817-3f781484d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(y_test[1])\n",
    "\n",
    "plt.imshow(X_test[1].reshape(28,28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a75354-8a08-47e0-8cd7-0106b54b6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test.reshape(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd3e6d-405f-4dcf-8afe-085561910aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.argmax(pred[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aeb13b-c957-4616-8e2c-56ad32f2a3f9",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798ad83-d8e8-42aa-b1b0-d253ac264270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ytrue = pd.Series(np.argmax(y_test, axis= 1), name = 'ytrue')\n",
    "ypred = pd.Series(np.argmax(pred, axis= 1), name = 'pred')\n",
    "pd.crosstab(ytrue, ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1493c26-bcf7-459d-97c8-749051c21e9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lernkurve plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab874b-e87e-44c9-a3aa-a78250e379fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "limits = [100, 1000, 3000, 9000, 10500]\n",
    "test_accs = []\n",
    "train_accs = []\n",
    "for limit in limits:\n",
    "    model = NeuralNetwork(0.25)\n",
    "\n",
    "    for i in range(0, 100):\n",
    "        for j in range(0, limit, 100):\n",
    "           model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    test_acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    y_train_pred = model.predict(X_train / 255.)\n",
    "    y_train_pred = np.argmax(y_train_pred, axis=0)\n",
    "    train_acc = np.mean(y_train_pred == y_train)\n",
    "\n",
    "    test_accs.append(test_acc)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(limits, train_accs, label=\"Training\")\n",
    "plt.plot(limits, test_accs, label=\"Test\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659348c4-222c-48a9-ac03-1f679fe47c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b43b0a-a629-4314-9afe-824d4892292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13167647-efc2-4aa4-89b6-8a39874c8ca9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Lernrate plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c7e65-2a20-4f9d-9d07-aa254422c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(100, 784)\n",
    "        self.w1 = np.random.randn(5, 100)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "epochs = []\n",
    "costs = []\n",
    "accs = []\n",
    "\n",
    "for i in range(0, 50):\n",
    "    for j in range(0, 10500, 100):\n",
    "        model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "    cost = model.cost(model.predict(X_train), y_train_oh)\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    epochs.append(i + 1)\n",
    "    costs.append(cost)\n",
    "    accs.append(acc)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(epochs, costs, label=\"Kosten\")\n",
    "plt.plot(epochs, accs, label=\"Genauigkeit\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d39364-d08d-416e-a7b0-decab5a28071",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.mean(y_test_pred == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d12db-fe89-4e9b-b113-c288b426a7ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Netzwerkgröße"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74d34e-1324-446b-8b8f-6d1f5167b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, lr = 0.1, hidden_size = 100):\n",
    "        self.lr = lr\n",
    "\n",
    "        self.w0 = np.random.randn(hidden_size, 784)\n",
    "        self.w1 = np.random.randn(5, hidden_size)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "\n",
    "        e1 = y.T - pred\n",
    "        e0 = e1.T @ self.w1\n",
    "\n",
    "        dw1 = e1 * pred * (1 - pred) @ a0.T / len(X)\n",
    "        dw0 = e0.T * a0 * (1 - a0) @ X / len(X)\n",
    "\n",
    "        assert dw1.shape == self.w1.shape\n",
    "        assert dw0.shape == self.w0.shape\n",
    "\n",
    "        self.w1 = self.w1 + self.lr * dw1\n",
    "        self.w0 = self.w0 + self.lr * dw0\n",
    "\n",
    "        # print(\"Kosten: \" + str(self.cost(pred, y)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        a0 = self.activation(self.w0 @ X.T)\n",
    "        pred = self.activation(self.w1 @ a0)\n",
    "        return pred\n",
    "\n",
    "    def cost(self, pred, y):\n",
    "        # SUM((y - pred)^2)\n",
    "        s = (1 / 2) * (y.T - pred) ** 2\n",
    "        return np.mean(np.sum(s, axis=0))\n",
    "\n",
    "for hidden_size in [500, 600, 700, 800]:\n",
    "\n",
    "    model = NeuralNetwork(0.3, hidden_size)\n",
    "\n",
    "    for i in range(0, 25):\n",
    "        for j in range(0, 10500, 100):\n",
    "            model.train(X_train[j:(j + 100), :] / 255., y_train_oh[j:(j + 100), :])\n",
    "\n",
    "        # cost = model.cost(model.predict(X_train), y_train_oh)\n",
    "\n",
    "    y_test_pred = model.predict(X_test / 255.)\n",
    "    y_test_pred = np.argmax(y_test_pred, axis=0)\n",
    "    acc = np.mean(y_test_pred == y_test)\n",
    "\n",
    "    print(str(hidden_size) + \": \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0987adc-cc91-4ec7-9091-ed042449438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(0, len(X_test)):\n",
    "    if y_test_pred[i] == 2 and y_test[i] ==1:\n",
    "        count += 1\n",
    "        plt.imshow(X_test[i].reshape(28, 28))\n",
    "        plt.show()\n",
    "        print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}