%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Start}}

\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{My sample book}
\date{Feb 06, 2022}
\release{}
\author{The Jupyter Book Community}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{00_Intro/intro::doc}}


\sphinxAtStartPar
This is a small sample book to give you a feel for how book content is
structured.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Here is a note!
\end{sphinxadmonition}

\sphinxAtStartPar
And here is a code block:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{e} \PYG{o}{=} \PYG{n}{mc}\PYG{o}{\PYGZca{}}\PYG{l+m+mi}{2}
\end{sphinxVerbatim}

\sphinxAtStartPar
Check out the content pages bundled with this sample book to see more.

\sphinxAtStartPar
\sphinxstylestrong{What is possible with the Jupyter Book?}

\sphinxAtStartPar
Die Idee ist es, ein Video der jeweiligen Schraube aufzunehmen und aus diesem Video die Bilder mit Python zu extrahieren. Um es am Anfang etwas einfacher zu gestalten nehmen wir zunächst nur die Schraubenköpfe. Wir beginnen mit 100 Bildern pro Schraube. Diese ersten 100 Bilder sollen alle unter gleichen Bedingungen aufgenommen werden, sie werden zum trainieren des Modells genutzt. Die Testbilder werden werden separat aufgenommen, sie können Schatten enthalten und in unterschiedlicher Beleuchtung aufgenommen werden um die Leistungsfähigkeit des Modells einschätzen zu können.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\Large Markdown Files}
\end{DUlineblock}

\sphinxAtStartPar
Whether you write your book’s content in Jupyter Notebooks (\sphinxcode{\sphinxupquote{.ipynb}}) or
in regular markdown files (\sphinxcode{\sphinxupquote{.md}}), you’ll write in the same flavor of markdown
called \sphinxstylestrong{MyST Markdown}.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large What is MyST?}
\end{DUlineblock}

\sphinxAtStartPar
MyST stands for “Markedly Structured Text”. It
is a slight variation on a flavor of markdown called “CommonMark” markdown,
with small syntax extensions to allow you to write \sphinxstylestrong{roles} and \sphinxstylestrong{directives}
in the Sphinx ecosystem.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large What are roles and directives?}
\end{DUlineblock}

\sphinxAtStartPar
Roles and directives are two of the most powerful tools in Jupyter Book. They
are kind of like functions, but written in a markup language. They both
serve a similar purpose, but \sphinxstylestrong{roles are written in one line}, whereas
\sphinxstylestrong{directives span many lines}. They both accept different kinds of inputs,
and what they do with those inputs depends on the specific role or directive
that is being called.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Using a directive}
\end{DUlineblock}

\sphinxAtStartPar
At its simplest, you can insert a directive into your book’s content like so:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
```\PYGZob{}mydirectivename\PYGZcb{}
My directive content
```
\end{sphinxVerbatim}

\sphinxAtStartPar
This will only work if a directive with name \sphinxcode{\sphinxupquote{mydirectivename}} already exists
(which it doesn’t). There are many pre\sphinxhyphen{}defined directives associated with
Jupyter Book. For example, to insert a note box into your content, you can
use the following directive:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
```\PYGZob{}note\PYGZcb{}
Here is a note
```
\end{sphinxVerbatim}

\sphinxAtStartPar
This results in:

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Here is a note
\end{sphinxadmonition}

\sphinxAtStartPar
In your built book.

\sphinxAtStartPar
For more information on writing directives, see the
\sphinxhref{https://myst-parser.readthedocs.io/}{MyST documentation}.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Using a role}
\end{DUlineblock}

\sphinxAtStartPar
Roles are very similar to directives, but they are less\sphinxhyphen{}complex and written
entirely on one line. You can insert a role into your book’s content with
this pattern:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Some content \PYGZob{}rolename\PYGZcb{}`and here is my role\PYGZsq{}s content!`
\end{sphinxVerbatim}

\sphinxAtStartPar
Again, roles will only work if \sphinxcode{\sphinxupquote{rolename}} is a valid role’s name. For example,
the \sphinxcode{\sphinxupquote{doc}} role can be used to refer to another page in your book. You can
refer directly to another page by its relative path. For example, the
role syntax \sphinxcode{\sphinxupquote{\{doc\}`intro`}} will result in: {\hyperref[\detokenize{00_Intro/intro::doc}]{\sphinxcrossref{\DUrole{doc}{Jupyter Book}}}}.

\sphinxAtStartPar
For more information on writing roles, see the
\sphinxhref{https://myst-parser.readthedocs.io/}{MyST documentation}.

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Adding a citation}
\end{DUlineblock}

\sphinxAtStartPar
You can also cite references that are stored in a \sphinxcode{\sphinxupquote{bibtex}} file. For example,
the following syntax: \sphinxcode{\sphinxupquote{\{cite\}`holdgraf\_evidence\_2014`}} will render like
this: {[}\hyperlink{cite.00_Intro/intro:id3}{HdHPK14}{]}.

\sphinxAtStartPar
Moreover, you can insert a bibliography into your page with this syntax:
The \sphinxcode{\sphinxupquote{\{bibliography\}}} directive must be used for all the \sphinxcode{\sphinxupquote{\{cite\}}} roles to
render properly.
For example, if the references for your book are stored in \sphinxcode{\sphinxupquote{references.bib}},
then the bibliography is inserted with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
```\PYGZob{}bibliography\PYGZcb{}
```
\end{sphinxVerbatim}

\sphinxAtStartPar
Resulting in a rendered bibliography that looks like:

\sphinxAtStartPar


\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Executing code in your markdown files}
\end{DUlineblock}

\sphinxAtStartPar
If you’d like to include computational content inside these markdown files,
you can use MyST Markdown to define cells that will be executed when your
book is built. Jupyter Book uses \sphinxstyleemphasis{jupytext} to do this.

\sphinxAtStartPar
First, add Jupytext metadata to the file. For example, to add Jupytext metadata
to this markdown page, run this command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{jupyter}\PYG{o}{\PYGZhy{}}\PYG{n}{book} \PYG{n}{myst} \PYG{n}{init} \PYG{n}{markdown}\PYG{o}{.}\PYG{n}{md}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once a markdown file has Jupytext metadata in it, you can add the following
directive to run the code at build time:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
```\PYGZob{}code\PYGZhy{}cell\PYGZcb{}
print(\PYGZdq{}Here is some code to execute\PYGZdq{})
```
\end{sphinxVerbatim}

\sphinxAtStartPar
When your book is built, the contents of any \sphinxcode{\sphinxupquote{\{code\sphinxhyphen{}cell\}}} blocks will be
executed with your default Jupyter kernel, and their outputs will be displayed
in\sphinxhyphen{}line with the rest of your content.

\sphinxAtStartPar
For more information about executing computational content with Jupyter Book,
see \sphinxhref{https://myst-nb.readthedocs.io/}{The MyST\sphinxhyphen{}NB documentation}.


\part{Start}


\chapter{Herzlich Willkommen}
\label{\detokenize{00_Intro/markdown:herzlich-willkommen}}\label{\detokenize{00_Intro/markdown::doc}}
\sphinxAtStartPar
Diese Masterarbeit behandelt die Erkennung von Schrauben auf Bildern und soll den Einstieg in das Thema Neuronale Netze erleichtern.


\chapter{Content with notebooks}
\label{\detokenize{00_Intro/notebooks:content-with-notebooks}}\label{\detokenize{00_Intro/notebooks::doc}}
\sphinxAtStartPar
You can also create content with Jupyter Notebooks. This means that you can include
code blocks and their outputs in your book.


\section{Markdown + notebooks}
\label{\detokenize{00_Intro/notebooks:markdown-notebooks}}
\sphinxAtStartPar
As it is markdown, you can embed images, HTML, etc into your posts!

\sphinxAtStartPar
\sphinxincludegraphics{{C:/Users/Martin/OneDrive/Masterthesis_2022/_build/.doctrees\images\86f925bcfc7b65561516d54179f9c6a9096d9072\logo-wide}.svg}

\sphinxAtStartPar
You can also \(add_{math}\) and
\begin{equation*}
\begin{split}
math^{blocks}
\end{split}
\end{equation*}
\sphinxAtStartPar
or
\begin{equation*}
\begin{split}
\begin{aligned}
\mbox{mean} la_{tex} \\ \\
math blocks
\end{aligned}
\end{split}
\end{equation*}
\sphinxAtStartPar
But make sure you \$Escape \$your \$dollar signs \$you want to keep!


\section{MyST markdown}
\label{\detokenize{00_Intro/notebooks:myst-markdown}}
\sphinxAtStartPar
MyST markdown works in Jupyter Notebooks as well. For more information about MyST markdown, check
out \sphinxhref{https://jupyterbook.org/content/myst.html}{the MyST guide in Jupyter Book},
or see \sphinxhref{https://myst-parser.readthedocs.io/en/latest/}{the MyST markdown documentation}.


\section{Code blocks and outputs}
\label{\detokenize{00_Intro/notebooks:code-blocks-and-outputs}}
\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
Jupyter Book will also embed your code blocks and output in your book.
For example, here’s some sample Matplotlib code:
\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k+kn}{import} \PYG{n}{rcParams}\PYG{p}{,} \PYG{n}{cycler}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{ion}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZlt{}matplotlib.pyplot.\PYGZus{}IonContext at 0x2588535c688\PYGZgt{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Fixing random state for reproducibility}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{seed}\PYG{p}{(}\PYG{l+m+mi}{19680801}\PYG{p}{)}

\PYG{n}{N} \PYG{o}{=} \PYG{l+m+mi}{10}
\PYG{n}{data} \PYG{o}{=} \PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{logspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)} \PYG{o}{+} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)} \PYG{o}{+} \PYG{n}{ii} \PYG{k}{for} \PYG{n}{ii} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{N}\PYG{p}{)}\PYG{p}{]}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{o}{.}\PYG{n}{T}
\PYG{n}{cmap} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{cm}\PYG{o}{.}\PYG{n}{coolwarm}
\PYG{n}{rcParams}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{axes.prop\PYGZus{}cycle}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{cycler}\PYG{p}{(}\PYG{n}{color}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{N}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}


\PYG{k+kn}{from} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{lines} \PYG{k+kn}{import} \PYG{n}{Line2D}
\PYG{n}{custom\PYGZus{}lines} \PYG{o}{=} \PYG{p}{[}\PYG{n}{Line2D}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{(}\PYG{l+m+mf}{0.}\PYG{p}{)}\PYG{p}{,} \PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{,}
                \PYG{n}{Line2D}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{(}\PYG{l+m+mf}{.5}\PYG{p}{)}\PYG{p}{,} \PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{,}
                \PYG{n}{Line2D}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{color}\PYG{o}{=}\PYG{n}{cmap}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{)}\PYG{p}{,} \PYG{n}{lw}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{]}

\PYG{n}{fig}\PYG{p}{,} \PYG{n}{ax} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{lines} \PYG{o}{=} \PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{legend}\PYG{p}{(}\PYG{n}{custom\PYGZus{}lines}\PYG{p}{,} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cold}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Medium}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Hot}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{notebooks_2_0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
There is a lot more that you can do with outputs (such as including interactive outputs)
with your book. For more information about this, see \sphinxhref{https://jupyterbook.org}{the Jupyter Book documentation}


\part{Bilderdatenbank}


\chapter{Bilder aus Video}
\label{\detokenize{01_Bilderdatenbank/video2frames:bilder-aus-video}}\label{\detokenize{01_Bilderdatenbank/video2frames::doc}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{pozi_quer}.PNG}
\caption{This is a Pozidriv \sphinxstylestrong{Schraube}!}\label{\detokenize{01_Bilderdatenbank/video2frames:markdown-fig}}\end{figure}

\sphinxAtStartPar
Hier ist ein \sphinxstylestrong{\sphinxhref{https://towardsdatascience.com/how-do-you-know-you-have-enough-training-data-ad9b1fd679ee}{Link}}.

\sphinxAtStartPar
Das Bild der Schraube stammt aus einem Video, welches mit einem Iphone 12 pro aufgenommen wurde. Die Aufnahme ist sehr detailreich, das Pozidriv Profil sowie auch Beschädigungen, Rost und Ablagerungen auf der Oberfläche, sind gut zu erkennen.

\sphinxAtStartPar
Nachdem wir die Videos aufgenommen haben und die Softwareumgebung installiert ist, beginnen wir mit dem Python Programm zum Extrahieren von Bildern aus Videos:

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Es stellt sich die Frage wie detailreich die Schraubenbilder sein müssen um eine gute Erkennung zu ermöglichen?
\end{sphinxadmonition}


\section{Extracting and Saving Video Frames using OpenCV\sphinxhyphen{}Python}
\label{\detokenize{01_Bilderdatenbank/video2frames:extracting-and-saving-video-frames-using-opencv-python}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} OpenCV importieren:}

\PYG{k+kn}{import} \PYG{n+nn}{cv2}



\PYG{c+c1}{\PYGZsh{} path = \PYGZsq{}relativer Speicherpfad / Dateiname\PYGZsq{}:}

\PYG{n}{path} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pozi/pozi}\PYG{l+s+s1}{\PYGZsq{}}



\PYG{c+c1}{\PYGZsh{} Video laden:}

\PYG{n}{cap} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{VideoCapture}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pozi.MOV}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{i} \PYG{o}{=} \PYG{l+m+mi}{0}


\PYG{c+c1}{\PYGZsh{} Prüfen ob ein Video geladen wurde:}

\PYG{k}{if} \PYG{n}{cap}\PYG{o}{.}\PYG{n}{isOpened}\PYG{p}{(}\PYG{p}{)} \PYG{o}{==} \PYG{k+kc}{False}\PYG{p}{:}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ERROR: Datei nicht gefunden}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

    
    
\PYG{c+c1}{\PYGZsh{} Die Frames des Videos lesen:    }
    
\PYG{k}{while}\PYG{p}{(}\PYG{n}{cap}\PYG{o}{.}\PYG{n}{isOpened}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{ret}\PYG{p}{,} \PYG{n}{frame} \PYG{o}{=} \PYG{n}{cap}\PYG{o}{.}\PYG{n}{read}\PYG{p}{(}\PYG{p}{)}
     
    \PYG{c+c1}{\PYGZsh{} sobald keine Frames mehr gelesen werden können (ret==False) wird abgebrochen:}
    \PYG{k}{if} \PYG{n}{ret} \PYG{o}{==} \PYG{k+kc}{False}\PYG{p}{:}
        \PYG{k}{break}
     
    \PYG{c+c1}{\PYGZsh{} Die Frames speichern}
    \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imwrite}\PYG{p}{(}\PYG{n}{path}\PYG{o}{+}\PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{o}{+}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{.jpg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{frame}\PYG{p}{)}
    \PYG{n}{i} \PYG{o}{+}\PYG{o}{=} \PYG{l+m+mi}{1}
 

\PYG{n}{cap}\PYG{o}{.}\PYG{n}{release}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cv}\PYG{o}{.}\PYG{n}{destroyAllWindows}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Resize Image}
\label{\detokenize{01_Bilderdatenbank/video2frames:resize-image}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{cv2}

\PYG{n}{img} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pozi/pozi800.jpg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{IMREAD\PYGZus{}UNCHANGED}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Original Dimensions : }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}

\PYG{n}{scale\PYGZus{}percent} \PYG{o}{=} \PYG{l+m+mi}{50} \PYG{c+c1}{\PYGZsh{} percent of original size}
\PYG{n}{width} \PYG{o}{=} \PYG{n+nb}{int}\PYG{p}{(}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{*} \PYG{n}{scale\PYGZus{}percent} \PYG{o}{/} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{height} \PYG{o}{=} \PYG{n+nb}{int}\PYG{p}{(}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{*} \PYG{n}{scale\PYGZus{}percent} \PYG{o}{/} \PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{n}{dim} \PYG{o}{=} \PYG{p}{(}\PYG{n}{width}\PYG{p}{,} \PYG{n}{height}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}resize image}
\PYG{n}{resized} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{resize}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{dim}\PYG{p}{,} \PYG{n}{interpolation} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{INTER\PYGZus{}AREA}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Resized Dimensions : }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{resized}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}

\PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Resized image}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{resized}\PYG{p}{)}
\PYG{n}{cv2}\PYG{o}{.}\PYG{n}{waitKey}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n}{cv2}\PYG{o}{.}\PYG{n}{destroyAllWindows}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZti{}}\PYGZbs{}\PYG{n}{AppData}\PYGZbs{}\PYG{n}{Local}\PYGZbs{}\PYG{n}{Temp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}23276}\PYG{o}{/}\PYG{l+m+mf}{1098803240.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{k+kn}{import} \PYG{n+nn}{cv2}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{2} 
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{3} \PYG{n}{img} \PYG{o}{=} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{imread}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pozi/pozi800.jpg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{cv2}\PYG{o}{.}\PYG{n}{IMREAD\PYGZus{}UNCHANGED}\PYG{p}{)}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{4} 
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{5} \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Original Dimensions : }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{img}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}cv2\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\chapter{Image Data Generator}
\label{\detokenize{01_Bilderdatenbank/imagedatagen:image-data-generator}}\label{\detokenize{01_Bilderdatenbank/imagedatagen::doc}}

\section{Preprocessing}
\label{\detokenize{01_Bilderdatenbank/imagedatagen:preprocessing}}
\sphinxAtStartPar
Mit dem Image Data Generator werden wir unsere Bilder weiterverarbeiten. Wir werden den Datensatz künstlich erweitern um so das Modell robuster zu machen.


\section{Bilder in Numpy Array speichern}
\label{\detokenize{01_Bilderdatenbank/imagedatagen:bilder-in-numpy-array-speichern}}
\sphinxAtStartPar
Um sehr viele Bilder abzuspeichern in einer Form die für das CNN passend ist, werden die Bilder in ein Numpy Array gespeichert. Dieses Numpy Array ist zunächst 3 Dimensional, wird später aber noch auf 4D erweitert.

\sphinxAtStartPar
Wie man nun die Bilder oder besser gesagt die Pixelwerte in ein Numpy Array speichert zeigt der folgende Programmcode:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} lob importieren}
\PYG{k+kn}{import} \PYG{n+nn}{glob}

\PYG{c+c1}{\PYGZsh{} import numpy}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{c+c1}{\PYGZsh{} import Image from PIL}
\PYG{k+kn}{from} \PYG{n+nn}{PIL} \PYG{k+kn}{import} \PYG{n}{Image}

\PYG{c+c1}{\PYGZsh{} Dateinamen der Bilder in filelist speichern}
\PYG{n}{filelist} \PYG{o}{=} \PYG{n}{glob}\PYG{o}{.}\PYG{n}{glob}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../pozi/*.jpg}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Alle Bilder nacheinander öffnen und hintereinander in ein Numpy Array speichern}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{Image}\PYG{o}{.}\PYG{n}{open}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}\PYG{p}{)} \PYG{k}{for} \PYG{n}{fname} \PYG{o+ow}{in} \PYG{n}{filelist}\PYG{p}{]}\PYG{p}{)}

\end{sphinxVerbatim}


\section{Labels erstellen}
\label{\detokenize{01_Bilderdatenbank/imagedatagen:labels-erstellen}}
\sphinxAtStartPar
Wie erstellt man die Labels?


\section{Datensatz in Numpy Array exportieren}
\label{\detokenize{01_Bilderdatenbank/imagedatagen:datensatz-in-numpy-array-exportieren}}
\sphinxAtStartPar
(X\_Train, y\_Train, X\_Test, y\_Test) in ein Numpy Array gemeinsam speichern:


\part{Neuronales Netz}


\chapter{Ein einzelnes Neuron}
\label{\detokenize{02_NN/einzelnes_neuron:ein-einzelnes-neuron}}\label{\detokenize{02_NN/einzelnes_neuron::doc}}
\sphinxAtStartPar
Um den Einstieg zu erleichtern, schauen wir uns zunächst ein einzelnes Neuron genauer an.

\sphinxAtStartPar
\sphinxstylestrong{Lernziele:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
verstehen was ein einzelnes Neuron macht

\item {} 
\sphinxAtStartPar
Ein einzelnes Neuron in Python modellieren

\item {} 
\sphinxAtStartPar
die Konzepte hinter Neuronalen Netzen besser verstehen

\end{itemize}

\sphinxAtStartPar
Ein einzelnes Neuron besitzt mehrere, gewichtete Eingänge und einen Ausgang siehe folgende Abbildung.

\sphinxAtStartPar
Weitere Informationen im Artikel,
\sphinxhref{https://www.informatik-aktuell.de/betrieb/kuenstliche-intelligenz/neuronale-netze-ein-blick-in-die-black-box.html}{Neuronale Netze: Ein Blick in die Blackbox}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{neuron}.png}
\caption{Modell eines einzelnen Neurons.}\label{\detokenize{02_NN/einzelnes_neuron:markdown-fig}}\end{figure}

\sphinxAtStartPar
Die gewichteten Eingabewerte werden mit einem Bias verrechnet, vom Neuron aufsummiert und durch eine Aktivierungsfunktion wird ein Ausgabewert berechnet.

\sphinxAtStartPar
Wir beginnen zunächst mit dem einfachsten Fall:


\chapter{Ein vereinfachtes Neuron}
\label{\detokenize{02_NN/einzelnes_neuron:ein-vereinfachtes-neuron}}
\sphinxAtStartPar
In der Abbildung ist ein vereinfachtes künstliches Neuron zu sehen. Dieses Neuron besitzt keine Aktivierungsfunktion und keinen Bias\sphinxhyphen{}Term. Es besitzt lediglich eine Summierfunktion.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{neuron_summe}.png}
\caption{Modell eines einzelnen Neurons ohne Bias und Aktivierungsfunktion.}\label{\detokenize{02_NN/einzelnes_neuron:id1}}\end{figure}

\sphinxAtStartPar
Die \sphinxstylestrong{Eingabedaten X} werden nun mit den \sphinxstylestrong{Gewichten w} verrechnet. Das Neuron bildet anschließend die Summe und gibt diese als \sphinxstylestrong{Ausgabewert y} aus. Wie die Werte für die Gewichte bestimmt werden kann man im \sphinxstylestrong{Kapitel: Lernvorgang} nachlesen. Für das weitere Vorgehen, reicht es aus, zu wissen, dass es diese Gewichte gibt.

\sphinxAtStartPar
Anhand dieses einfachen Neurons kann man den konzeptionellen Aufbau Neuronaler Netze besser verstehen. Was dieses Neuron kann, schauen wir uns anhand eines Beispiels in Python an.


\chapter{Lineare Regression ohne Bias}
\label{\detokenize{02_NN/einzelnes_neuron:lineare-regression-ohne-bias}}
\sphinxAtStartPar
evt weglassen und nur mit Bias erklären

\sphinxAtStartPar
\sphinxhref{https://towardsdatascience.com/linear-regression-using-python-b136c91bf0a2}{Linear Regression and Bias}

\sphinxAtStartPar
\sphinxstylestrong{Beispiel: Millimeter in Zoll umrechnen}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X} \PYG{o}{=} \PYG{p}{[}
    \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{15}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{]}
\PYG{p}{]}

\PYG{n}{y} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+m+mf}{0.0393701}\PYG{p}{,}
    \PYG{l+m+mf}{0.590551}\PYG{p}{,}
    \PYG{l+m+mf}{2.3622}
\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k+kn}{import} \PYG{n}{linear\PYGZus{}model}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{linear\PYGZus{}model}\PYG{o}{.}\PYG{n}{LinearRegression}\PYG{p}{(}\PYG{n}{fit\PYGZus{}intercept} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZti{}}\PYGZbs{}\PYG{n}{AppData}\PYGZbs{}\PYG{n}{Local}\PYGZbs{}\PYG{n}{Temp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}15240}\PYG{o}{/}\PYG{l+m+mf}{2661756792.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k+kn}{import} \PYG{n}{linear\PYGZus{}model}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{2} \PYG{n}{model} \PYG{o}{=} \PYG{n}{linear\PYGZus{}model}\PYG{o}{.}\PYG{n}{LinearRegression}\PYG{p}{(}\PYG{n}{fit\PYGZus{}intercept} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{)}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{3} \PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}sklearn\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Das Modell hat nun den Zusammenhang der Trainingsdaten gelernt.
Das gelernte Gewicht entspricht dabei der Steigung der Regressionsgeraden.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Steigung bzw Koeffizient oder Gewicht}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{coef\PYGZus{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[1.8]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Diesen gelernten Zusammenhang können wir nun auch auf neue Daten anwenden:

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+m+mi}{100} \PYG{o}{*} \PYG{l+m+mf}{0.03937}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
3.9370000000000003
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Eine “Vorhersage” für eine Reihe an Werten bekommt man mit der predict\sphinxhyphen{}Methode:

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}
    \PYG{p}{[}\PYG{l+m+mi}{120}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{130}\PYG{p}{]}
\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([4.72440047, 5.11810051])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Das einzelne Neuron ist bereits in der Lage den Zusammenhang zwischen Millimeter und Zoll aus den Trainingsdaten zu lernen.


\chapter{Lineare Regression mit Bias}
\label{\detokenize{02_NN/einzelnes_neuron:lineare-regression-mit-bias}}
\sphinxAtStartPar
\sphinxstylestrong{Beispiel: Grad Celsius in Fahrenheit umrechnen}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{neuron_bias}.png}
\caption{Modell eines einzelnen Neurons mit Bias.}\label{\detokenize{02_NN/einzelnes_neuron:id2}}\end{figure}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X} \PYG{o}{=} \PYG{p}{[}
    \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{]}
\PYG{p}{]}

\PYG{n}{y} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+m+mi}{14}\PYG{p}{,}
    \PYG{l+m+mi}{32}\PYG{p}{,}
    \PYG{l+m+mi}{68}
\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k+kn}{import} \PYG{n}{linear\PYGZus{}model}
\PYG{n}{model} \PYG{o}{=} \PYG{n}{linear\PYGZus{}model}\PYG{o}{.}\PYG{n}{LinearRegression}\PYG{p}{(}\PYG{n}{fit\PYGZus{}intercept} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
LinearRegression()
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Dadurch, dass wir dem Modell mit \sphinxstylestrong{fit\_intercept = True} einen weiteren Freiheitsgrad zur Verfügung stellen, ist das Modell in der Lage den Zusammenhang zwischen Grad Celsius und Fahrenheit zu lernen.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{coef\PYGZus{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{intercept\PYGZus{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[1.8]
32.0
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Das Neuron hat den Zusammenhang korrekt gelernt.

\sphinxAtStartPar
Die Berechnungsformel lautet:
\sphinxstylestrong{°F = °C * 1,8 + 32 (von Celsius nach Fahrenheit)}

\sphinxAtStartPar
\sphinxstylestrong{Beispiel: Verbrauch von Autos:}

\sphinxAtStartPar
Ein weiteres berühmtes Machinelearningbeispiel ist der \sphinxhref{https://archive.ics.uci.edu/ml/datasets/auto+mpg}{MPG Datensatz}.

\sphinxAtStartPar
\sphinxstylestrong{Verbrauch von Autos vorhersagen}

\sphinxAtStartPar
\sphinxstylestrong{Aufgabe:}

\sphinxAtStartPar
Eine Firma hat ein neues Auto angekündigt, aber noch keine Verbrauchsdaten angegeben. Kannst du den Verbrauch (in l/100km) des Autos schätzen, indem du ein Modell trainierst?

\sphinxAtStartPar
Das Auto hat:
\begin{itemize}
\item {} 
\sphinxAtStartPar
8 Zylinder

\item {} 
\sphinxAtStartPar
200PS

\item {} 
\sphinxAtStartPar
2500kg

\end{itemize}

\sphinxAtStartPar
Lese dazu die Datei \sphinxcode{\sphinxupquote{mpg\sphinxhyphen{}dataset.csv}} ein. Trainiere anschließend ein Modell, und sage den Verbrauch (in l/100km) dieses Autos vorher!

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{mpg\PYGZus{}to\PYGZus{}l\PYGZus{}per\PYGZus{}100km}\PYG{p}{(}\PYG{n}{mpg}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{LITERS\PYGZus{}PER\PYGZus{}GALLON} \PYG{o}{=} \PYG{l+m+mf}{3.785411784}
    \PYG{n}{KILOMETERS\PYGZus{}PER\PYGZus{}MILES} \PYG{o}{=} \PYG{l+m+mf}{1.609344}

    \PYG{k}{return} \PYG{p}{(}\PYG{l+m+mi}{100} \PYG{o}{*} \PYG{n}{LITERS\PYGZus{}PER\PYGZus{}GALLON}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{n}{KILOMETERS\PYGZus{}PER\PYGZus{}MILES} \PYG{o}{*} \PYG{n}{mpg}\PYG{p}{)}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{mpg\PYGZus{}to\PYGZus{}l\PYGZus{}per\PYGZus{}100km}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
2.352145833333333
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{n}{df} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mpg\PYGZhy{}dataset.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X} \PYG{o}{=} \PYG{n}{df}\PYG{p}{[}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{cylinders}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{horsepower}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{weight}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{y} \PYG{o}{=} \PYG{n}{mpg\PYGZus{}to\PYGZus{}l\PYGZus{}per\PYGZus{}100km}\PYG{p}{(}\PYG{n}{df}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mpg}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LinearRegression}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{LinearRegression}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
LinearRegression()
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{coef\PYGZus{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{intercept\PYGZus{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[0.2757425  0.03284566 0.00229432]
\PYGZhy{}0.5232093219825558
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}
    \PYG{p}{[}\PYG{l+m+mi}{8}\PYG{p}{,} \PYG{l+m+mi}{200}\PYG{p}{,} \PYG{l+m+mi}{2500}\PYG{p}{]}
\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[13.98766161]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/martin/anaconda3/envs/scikit/lib/python3.9/site\PYGZhy{}packages/sklearn/base.py:445: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names
  warnings.warn(
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\chapter{Aktivierungsfunktion}
\label{\detokenize{02_NN/einzelnes_neuron:aktivierungsfunktion}}
\sphinxAtStartPar
\sphinxstylestrong{Wozu ist die Aktivierungsfunktion nötig?}

\sphinxAtStartPar
Die vereinfachten, linearen Neuronen lassen sich nicht hintereinander schalten/verknüpfen bzw macht es keinen Sinn dies zu tun. Eine Beispielrechnung verdeutlicht das:

\sphinxAtStartPar
\sphinxstylestrong{Beispiel:}
Am Eingang X liegt eine 5 an und am Ausgang soll eine 20 ausgegeben werden. Die beiden Gewichte bekommen 2 als Faktor. Das gleiche Ergebnis würde heraus kommen wenn man ein Neuron mit einem Gewicht und dem Faktor 4 verwendet.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{neuron_series}.png}
\caption{Lineare Neuronen in Reihe geschalten.}\label{\detokenize{02_NN/einzelnes_neuron:id3}}\end{figure}
\begin{itemize}
\item {} 
\sphinxAtStartPar
“hintereinanderschalten” von vereinfachten, linearen Neuronen ohne Aktivierungsfunktion nicht möglich

\item {} 
\sphinxAtStartPar
Bisher keine Ja/Nein Antworten oder Ausgabewerte zwischen 0 und 1 möglich

\end{itemize}

\sphinxAtStartPar
Die \sphinxstylestrong{Sigmoidfunktion} bildet die Ergebnisse auf den Zahlenbereich zwischen 0 und 1 ab. Die Ergebnisse können in der Form als eine Wahrscheinlichkeit aufgefasst werden:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{sigmoid}.png}
\caption{Modell eines einzelnen Neurons mit Bias und Aktivierungsfunktion.}\label{\detokenize{02_NN/einzelnes_neuron:id4}}\end{figure}


\chapter{Logistische Regression}
\label{\detokenize{02_NN/einzelnes_neuron:logistische-regression}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{neuron_activation}.png}
\caption{Modell eines einzelnen Neurons mit Bias und Aktivierungsfunktion.}\label{\detokenize{02_NN/einzelnes_neuron:id5}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Beispiel: Wird ein Studierender die Prüfung bestehen?}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} X = Wie viele Stunden wurde gelernt?}

\PYG{n}{X} \PYG{o}{=} \PYG{p}{[}
    \PYG{p}{[}\PYG{l+m+mi}{50}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{60}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{70}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{20}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mi}{30}\PYG{p}{]}\PYG{p}{,}
\PYG{p}{]}

\PYG{n}{y} \PYG{o}{=} \PYG{p}{[}
    \PYG{l+m+mi}{1}\PYG{p}{,} 
    \PYG{l+m+mi}{1}\PYG{p}{,}
    \PYG{l+m+mi}{1}\PYG{p}{,}
    \PYG{l+m+mi}{0}\PYG{p}{,} 
    \PYG{l+m+mi}{0}\PYG{p}{,} 
    \PYG{l+m+mi}{0}\PYG{p}{,}
\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{linear\PYGZus{}model} \PYG{k+kn}{import} \PYG{n}{LogisticRegression}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{LogisticRegression}\PYG{p}{(}\PYG{n}{C} \PYG{o}{=} \PYG{l+m+mi}{100000}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
LogisticRegression(C=100000)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}
    \PYG{p}{[}\PYG{l+m+mi}{44}\PYG{p}{]}
\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([1])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{predict\PYGZus{}proba}\PYG{p}{(}\PYG{p}{[}
    \PYG{p}{[}\PYG{l+m+mi}{35}\PYG{p}{]}
\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([[0.99873289, 0.00126711]])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\chapter{Wie lernt ein neuronales Netz?}
\label{\detokenize{02_NN/NN_learning:wie-lernt-ein-neuronales-netz}}\label{\detokenize{02_NN/NN_learning::doc}}
\sphinxAtStartPar
In diesem Abschnitt soll ein Einblick in den Aufbau und den Lernvorgang eines Neuronalen Netzes geschaffen werden.


\section{Hidden Layer}
\label{\detokenize{02_NN/NN_learning:hidden-layer}}
\sphinxAtStartPar
Bisher hatten wir nur ein Neuron. Da ein neuronales Netz aus mehreren solcher Neuronen aufgebaut ist, wollen wir uns in diesem Abschnitt damit befassen wie die einzelnen Neuronen zu einem Netz zusammen geschalten werden, wie diese einzelnen Neuronen arbeiten und wie es das Neuronale Netz schafft etwas zu lernen.

\sphinxAtStartPar
\sphinxstylestrong{Ein Netz aus mehreren Neuronen:}
Wir beginnen wieder mit einem einfachen Beispiel und verbinden ein paar Neuronen zu einem einfach NN:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Input Layer:} X1, X2, X3, b

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Hidden Layer} Neuron 1, Neuron 2, Neuron 3

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Output Layer} Neuron 4

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Beispiel:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
X1: Anzahl Zylinder

\item {} 
\sphinxAtStartPar
X2: Leistung kw

\item {} 
\sphinxAtStartPar
X3: Gewicht kg

\end{itemize}

\sphinxAtStartPar
Die Neuronen verteilen sich selbst auf verschiedene Features auf.
Jedes Neuron spezialisiert sich auf eine bestimmte Eigenschaft z.B.:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Neuron 1: Kleinwagen oder SUV (relevant: X1, X2, X3)

\item {} 
\sphinxAtStartPar
Neuron 2: Preis

\item {} 
\sphinxAtStartPar
Neuron 3: Beschleunigung (relevant: X2,X3)

\end{itemize}

\sphinxAtStartPar
Relevante Verbindungen werden vom Algorithmus verstärkt und nicht benötigte Verbindungen werden ignoriert (Gewicht wird sehr klein oder Null).

\sphinxAtStartPar
Der Output\sphinxhyphen{}Layer soll z.B. den Verbrauch vorhersagen und wird entsprechend jene Verbindungen verstärken, die besonders großen Einfluss auf den Verbrauch haben.

\sphinxAtStartPar
Die Aktualisierung der Gewichte hat einen großen Einfluss auf diesen Vorgang.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{hiddenLayer_1}.png}
\caption{Two\sphinxhyphen{}Layer\sphinxhyphen{}Neural Net.}\label{\detokenize{02_NN/NN_learning:two-layer-net}}\end{figure}

\sphinxAtStartPar
Weitere Informationen:
\sphinxhref{https://otexts.com/fpp2/nnetar.html}{Neural network architecture}.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Die Neuronen im Hidden Layer übernehmen jeweils verschiedene Hilfsaufgaben.. Der Output Layer kombiniert der Ergebnisse aus dem Hidden Layer und gibt eine Vorhersage aus.
\end{sphinxadmonition}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZhy{} Neuronale Netze mit einem beliebig großen Hidden\PYGZhy{}Layer können jede beliebige Funktion approximieren.
\PYGZhy{} je mehr Knoten das Netz besitzt, desto genauer kann es die math. Funktionen annähern.
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]

\end{sphinxVerbatim}


\section{Gewichte aktualisieren}
\label{\detokenize{02_NN/NN_learning:gewichte-aktualisieren}}
\sphinxAtStartPar
Nach der Initialisierung der Gewichte. Wird ein Ausgangswert berechnet. Passt dieser “Vorhersagewert” nicht zum richtigen Ergebnis, dann müssen die Gewichte dementsprechend angepasst werden, so dass das Ergebnis stimmt.

\sphinxAtStartPar
In der Abb. werden w1 und w2 so lange erhöht bis der Vorhersagewert zum richtigen Wert passt.

\sphinxAtStartPar
Das Neuron gibt 0.5 aus, obwohl der richtige Wert 0.75 ist. Das bedeutet, das Modell ist noch nicht so gut an die Daten angepasst. Um das Modell den Daten besser anzupassen, stehen nur die Gewichte als Stellschrauben zur Verfügung und diese können nun Stückweise erhöht werden bis das Modell die Daten ausreichend approximiert hat siehe Abbildung unten.


\section{Kostenfunktion}
\label{\detokenize{02_NN/NN_learning:kostenfunktion}}
\sphinxAtStartPar
Die Aktualisierung der Gewichte wird mit Hilfe einer Kostenfunktion erreicht. Es gibt verschiedene Kostenfunktionen, eine davon ist die \sphinxstylestrong{“quadratische Fehlerfunktion”}.

\sphinxAtStartPar
Weitere Kostenfunktionen und Informationen \sphinxhref{https://www.analyticsvidhya.com/blog/2021/02/cost-function-is-no-rocket-science/}{hier}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=750\sphinxpxdimen]{{weights_1}.png}
\caption{Kostenfunktion}\label{\detokenize{02_NN/NN_learning:id1}}\end{figure}

\sphinxAtStartPar
Die Quadrierung des Fehlers in der Kostenfunktion, bewirkt eine viel größere Bestrafung für größere Fehler.

\sphinxAtStartPar
Werden nun wie üblich mehrere Datensätze trainiert, müssen die Gewichte nach jedem Datensatz angepasst werden. Je nachdem wie die Vorhersage vom Ergebnis y abweicht.

\sphinxAtStartPar
Die Abbildung dient nur zur Veranschaulichung. Im Abschnitt Gradientenabstieg wird gezeigt wie die Kostenfunktion in Python minimiert wird.

\sphinxAtStartPar
Eine Kostenfunktion dient zum Minimieren des Fehlers. Man stellt eine Funktion auf, die den Fehler zwischen Schätzung und richtigem Wert berechnet und sucht dann die zugehörigen Gewichte, die den Fehler minimal werden lassen. Die Kosten C werden als Funktion der Gewichte formuliert. Da man es bei NN’s meistens mit komplexeren Funktionen und sehr vielen Gewichten zu tun hat, kann man das nicht mehr analytisch lösen. Für so einen Fall eignet sich das Gradientenabstiegsverfahren.


\section{Gradientenabstieg}
\label{\detokenize{02_NN/NN_learning:gradientenabstieg}}
\sphinxAtStartPar
Wichtig zum Verständnis des Trainings von neuronalen Netzen.

\sphinxAtStartPar
Wie aktualisiert der Computer mehrere tausend Gewichte?

\sphinxAtStartPar
Mit dem Gradientenabstiegsverfahren wird Schritt für Schritt das Minimum einer Funktion gesucht. Bei einfachen Funktionen kann man das noch analytisch lösen aber bei komplexeren Funtionen benötigt man das Gradientenabstiegsverfahren.

\sphinxAtStartPar
Wie findet man das Minimum bei komplexen Funktionen wie im Bild rechts?
Die Antwort lautet Gradientenabstiegsverfahren. Um dieses Verfahren näher zu erläutern beginnen wir wieder mit einem einfachen Fall,Für den gradient descent gab es bzgl Lernrate usw eine gute Geogebra erklärung in einem anderen Kurs von Jannis, diese Erklärung hier einfügen.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=500\sphinxpxdimen]{{gradient_descent}.png}
\caption{Die Gewichte der ersten Batch werden trainiert.}\label{\detokenize{02_NN/NN_learning:gradient-descent}}\end{figure}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}

\PYG{k}{def} \PYG{n+nf}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{x} \PYG{o}{*}\PYG{o}{*} \PYG{l+m+mi}{2} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{4} \PYG{o}{*} \PYG{n}{x} \PYG{o}{+} \PYG{l+m+mi}{5}


\PYG{k}{def} \PYG{n+nf}{f\PYGZus{}ableitung}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{x} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{4}


\PYG{n}{x} \PYG{o}{=} \PYG{l+m+mi}{5}

\PYG{c+c1}{\PYGZsh{}Schrittweite bzw Lernrate (lr):}
\PYG{n}{lr} \PYG{o}{=} \PYG{l+m+mf}{0.05}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,} \PYG{n}{c}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{r}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{25}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{steigung\PYGZus{}x} \PYG{o}{=} \PYG{n}{f\PYGZus{}ableitung}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}
    \PYG{n}{x} \PYG{o}{=} \PYG{n}{x} \PYG{o}{\PYGZhy{}} \PYG{n}{lr} \PYG{o}{*} \PYG{n}{steigung\PYGZus{}x}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{scatter}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{,} \PYG{n}{c}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{r}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}

\PYG{n}{xs} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{)}
\PYG{n}{ys} \PYG{o}{=} \PYG{n}{f}\PYG{p}{(}\PYG{n}{xs}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{xs}\PYG{p}{,} \PYG{n}{ys}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxadmonition}{important}{Important:}
\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Man kann nun mit der Lernrate experimentieren und z.B. einen großen Wert wählen. Es kann passieren, dass bei einer zu großen Schrittweite das Minimum übersprungen wird und somit nicht gefunden werden kann.
\end{sphinxadmonition}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Gut zu wissen}

\sphinxAtStartPar
In hochdimensionalen Räumen spielen lokale Minimas keine Rolle mehr. Erklärung folgt.
\end{sphinxadmonition}

\sphinxAtStartPar
In der Praxis hat man es eher mit komplexeren Funktionen mit mehreren Minimas zu tun. Die Gefahr, in einem lokalen Minimum stecken zu bleiben, ist in höher Dimensionalen Räumen zu vernachlässigen. Erklärung kommt später noch.

\sphinxAtStartPar
Geogebra dateien zeigen


\section{Stochastic Gradient Descent}
\label{\detokenize{02_NN/NN_learning:stochastic-gradient-descent}}
\sphinxAtStartPar
\sphinxstylestrong{Lernziele:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Was ist eine Batch?

\item {} 
\sphinxAtStartPar
Wozu braucht man Batches?

\item {} 
\sphinxAtStartPar
Welche Größe sollten die Batches haben?

\end{itemize}

\sphinxAtStartPar
Die Kosten für die gesamten Trainingsdaten zu berechnen und anschließend die Gewichte zu aktualisieren, würde bei sehr vielen Gewichten einen sehr hohen Rechenaufwand bedeuten, da die Kostenfunktion dann sehr viele variable Gewichte enthält. Deswegen geht man bei NN’s so vor, dass man nicht die Kosten für die gesamten Daten sondern nur für einzelne Batches berechnet und somit die Kosten approximiert. Das macht man dann für alle Batches und aktualisiert nach jedem Batch die Gewichte. So werden die Gewichte pro kompletten Durchgang mehrmals aktualisiert und nicht nur einmal am Ende eines kompletten Durchgangs. Das bringt allerdings mit sich, dass die Gewichte hin und her springen, im „ZickZack zum Minimum laufen“ Das führt insgesamt zu einem schnelleren Lernvorgang.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{gradient_batch1}.png}
\caption{erste Batch}\label{\detokenize{02_NN/NN_learning:id2}}\end{figure}

\sphinxAtStartPar
Anstatt alle Gewichte mit einmal zu bestimmen ist es vorteilhafter den Trainingssatz in einzelne Batches aufzuteilen, somit wird die Berechnung schneller und die Gewichte werden nach jedem Durchlauf angepasst.

\sphinxAtStartPar
Ablauf der Gewichtsanpassung für eine Batch:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Vorhersage machen

\item {} 
\sphinxAtStartPar
Kosten berechnen

\item {} 
\sphinxAtStartPar
Gewichte anpassen

\item {} 
\sphinxAtStartPar
dann nächste Batch

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{gradient_batch2}.png}
\caption{Zweite Batch}\label{\detokenize{02_NN/NN_learning:id3}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Begriffsdefinition:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Batch: Eine Gruppe von Trainingsdaten innerhalb des Datensatzes

\item {} 
\sphinxAtStartPar
Epoche: Alle Batches wurden einmal durchlaufen

\item {} 
\sphinxAtStartPar
Lernrate: Schrittgröße

\end{itemize}


\section{Backpropagation}
\label{\detokenize{02_NN/NN_learning:backpropagation}}
\sphinxAtStartPar
NN’s wurden erst durch Backpropagation Leistungsstark. Dadurch erst war es möglich, das gesamte NN zu trainieren.
Hier noch etwas Erklärung rund um Backpropagation und NN‘s allg. einfügen.
Wie werden die Gewichte der vorherigen Schicht aktualisiert?
Durch Backpropagation!
\begin{itemize}
\item {} 
\sphinxAtStartPar
verleiht den NN’s ihre Leistungsfähigkeit

\item {} 
\sphinxAtStartPar
verhalf zum Durchbruch von NN’s

\item {} 
\sphinxAtStartPar
Idee aus den 70ern

\item {} 
\sphinxAtStartPar
vorher konnte man nur Teile eines Netzes trainieren

\end{itemize}

\sphinxAtStartPar
Problematik beim Lernen von mehrschichtigen NN’s:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Wie werden die Gewichte einer vorherigen Schicht aktualisiert?

\end{itemize}

\sphinxAtStartPar
Lösung: Backpropagation…

\sphinxAtStartPar
Die Gewichte des gesamten NN werden immer wieder aktualisiert, solange bis der Vorhersagewert so nah wie möglich am gewünschten Wert liegt. Wie das genau gemacht wird, soll in diesem Abschnitt gezeigt werden.

\sphinxAtStartPar
\sphinxstylestrong{Ein grobes, einfaches Beispiel zur Backward\sphinxhyphen{}Propagation}:

\sphinxAtStartPar
Mit einem einfachen, groben Beispiel soll der Einstieg in das Verständis der Backpropagation erleichtert werden. Die Mathematik hinter der “Backpropagation” ist für Nicht\sphinxhyphen{}Informatiker/\sphinxhyphen{}mathematiker teilweise nicht so einfach zu verstehen. Für den Einstieg wird daher auf ein grobes Rechenbeispiel zurückgegriffen. Es soll an dieser Stelle zunächst nur der grobe Vorgang der BP veranschaulicht werden.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Es wird eine Vorhersage mit dem NN gemacht, diese Vorhersage \(\hat{y}\), weicht vom gewünschten / wahren Wert y ab

\item {} 
\sphinxAtStartPar
Die Abweichung e (Error) ist ein Maß dafür, wie stark die Vorhersage vom wahren Wert abweicht

\item {} 
\sphinxAtStartPar
Um die Abweichung zu minimieren müssen nun die Gewichte aktualisiert werden

\end{itemize}

\sphinxAtStartPar
Der Fehler e wird nun an die Ausgänge des Hidden\sphinxhyphen{}Layer transformiert:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{backprop1}.png}
\caption{Backpropagation}\label{\detokenize{02_NN/NN_learning:backprop1}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Initialisierung der Gewichte}

\sphinxAtStartPar
Die Initialisierung kann darüber entscheiden, ob das NN trainieren kann oder nicht.
Wie initialisieren wir die Gewichte? Mit Null wie im rechten Bild? Die Neuronen würden nur Nullen ausgeben. Das macht also keinen Sinn. Doch welche Werte soll man da am besten wählen?
Weiterhin dürfen die Gewichte nicht alle mit den gleichen Werten initialisiert werden. Das ist auch aktiver Forschungsgegenstand, denn bei mehrschichtigen Netzen wird es umso wichtiger die Gewichte „richtig“ bzw. nicht komplett falsch zu wählen.
Besser ist es, den Gewichten unterschiedliche Werte zu geben. Das können zufällige, eher kleine Werte sein. So ist sichergestellt, dass jedes Neuron eine andere Funktion berechnet. Somit kann dann auch die Backpropagation richtig arbeiten und die Gewichte anpassen.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{backprop2}.png}
\caption{Backpropagation2}\label{\detokenize{02_NN/NN_learning:id4}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{backprop3}.png}
\caption{Backpropagation3}\label{\detokenize{02_NN/NN_learning:id5}}\end{figure}


\chapter{Einfaches neuronales “from Scratch”}
\label{\detokenize{02_NN/NeuralNet_1:einfaches-neuronales-from-scratch}}\label{\detokenize{02_NN/NeuralNet_1::doc}}
\sphinxAtStartPar
In diesem Kapitel wird ein Neuronales Netz erstellt, welches entscheiden kann ob ein bestimmtes Objekt auf dem Bild zu sehen ist oder etwas anderes. Dieses Netz kann also erstmal nur eine Gruppe z.B. Sechskantschraube von allen anderen unterscheiden.

\sphinxAtStartPar
Wir werden 28x28 Pixel große Bilder von Schraubenköpfen verwenden.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{special} \PYG{k+kn}{import} \PYG{n}{expit}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{OneHotEncoder}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZti{}}\PYGZbs{}\PYG{n}{AppData}\PYGZbs{}\PYG{n}{Local}\PYGZbs{}\PYG{n}{Temp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}20476}\PYG{o}{/}\PYG{l+m+mf}{1027057003.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{1} \PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{2} \PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{3} \PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{special} \PYG{k+kn}{import} \PYG{n}{expit}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{4} \PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{OneHotEncoder}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{5} \PYG{k+kn}{import} \PYG{n+nn}{pickle}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}scipy\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{1.0}\PYG{o}{/}\PYG{l+m+mf}{255.0} 
\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{n}{oh} \PYG{o}{=} \PYG{n}{OneHotEncoder}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{y\PYGZus{}train\PYGZus{}oh} \PYG{o}{=} \PYG{n}{oh}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{y\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{o}{.}\PYG{n}{toarray}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{X\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{1.0}\PYG{o}{/}\PYG{l+m+mf}{255.0} 
\PYG{n}{y\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{y\PYGZus{}train\PYGZus{}oh}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 5)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{y\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 784)
(4500, 784)
(4500,)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{label check:}
\label{\detokenize{02_NN/NeuralNet_1:label-check}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{i}\PYG{o}{=}\PYG{l+m+mi}{8}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{y\PYGZus{}train}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{y\PYGZus{}train\PYGZus{}oh}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mi}{255}\PYG{p}{,}\PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{vmin}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{vmax}\PYG{o}{=}\PYG{l+m+mi}{255}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}
\PYG{c+c1}{\PYGZsh{} 0: innensechskant}
\PYG{c+c1}{\PYGZsh{} 1: philips}
\PYG{c+c1}{\PYGZsh{} 2: pozidriv}
\PYG{c+c1}{\PYGZsh{} 3: sechskant}
\PYG{c+c1}{\PYGZsh{} 4: torx}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 784)
(4500, 784)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{einfaches NN in Python}
\label{\detokenize{02_NN/NeuralNet_1:einfaches-nn-in-python}}
\sphinxAtStartPar
Ein NN ohne Deep Learning Bibliotheken:


\section{Genauigkeit interpretieren}
\label{\detokenize{02_NN/NeuralNet_1:genauigkeit-interpretieren}}
\sphinxAtStartPar
Was sagt eine genauigkeit von 90\% aus? Ist das gut oder schlecht?

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
\sphinxstylestrong{Beispiel:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
ja / nein

\item {} 
\sphinxAtStartPar
10\% / 90\%

\end{itemize}

\sphinxAtStartPar
Wenn das Modell immer “Nein” sagt wird es eine Genauigkeit von 90\% erreichen obwohl es alle “ja\sphinxhyphen{}Beispiele” nicht erkannt hat.
\end{sphinxadmonition}


\chapter{NN1 “Einer gegen Alle”}
\label{\detokenize{02_NN/NeuralNet_1_Keras:nn1-einer-gegen-alle}}\label{\detokenize{02_NN/NeuralNet_1_Keras::doc}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{c+c1}{\PYGZsh{}from scipy.special import expit}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{OneHotEncoder}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZti{}}\PYGZbs{}\PYG{n}{AppData}\PYGZbs{}\PYG{n}{Local}\PYGZbs{}\PYG{n}{Temp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}18516}\PYG{o}{/}\PYG{l+m+mf}{1473354027.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{2} \PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{3} \PYG{c+c1}{\PYGZsh{}from scipy.special import expit}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{4} \PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{OneHotEncoder}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{5} \PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{6} \PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}sklearn\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
In diesem Kapitel wird ein Neuronales Netz erstellt, welches entscheiden kann ob ein bestimmtes Objekt auf dem Bild zu sehen ist oder etwas anderes. Dieses Netz kann also erstmal nur eine Gruppe z.B. Sechskantschraube von allen anderen unterscheiden.

\sphinxAtStartPar
Wir werden 28x28 Pixel große Bilder von Schraubenköpfen verwenden.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}import tensorflow as tf}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{1.0}\PYG{o}{/}\PYG{l+m+mf}{255.0}
\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{int32}\PYG{p}{)}

\PYG{n}{X\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{1.0}\PYG{o}{/}\PYG{l+m+mf}{255.0}
\PYG{n}{y\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{int32}\PYG{p}{)}

\PYG{n}{y\PYGZus{}train\PYGZus{}A} \PYG{o}{=} \PYG{n}{y\PYGZus{}train} \PYG{o}{==} \PYG{l+m+mi}{3} \PYG{c+c1}{\PYGZsh{}sechskant soll erkannt werden}
\PYG{n}{y\PYGZus{}train\PYGZus{}B} \PYG{o}{=} \PYG{n}{y\PYGZus{}train} \PYG{o}{==} \PYG{l+m+mi}{2} \PYG{c+c1}{\PYGZsh{}pozidriv soll erkannt werden}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 784)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{i}\PYG{o}{=}\PYG{l+m+mi}{0}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{y\PYGZus{}train\PYGZus{}A}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}print(X\PYGZus{}train[i].reshape(28,28))}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{255.0}\PYG{p}{,}\PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{vmin}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{vmax}\PYG{o}{=}\PYG{l+m+mi}{255}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}
\PYG{c+c1}{\PYGZsh{} 0: innensechskant}
\PYG{c+c1}{\PYGZsh{} 1: philips}
\PYG{c+c1}{\PYGZsh{} 2: pozidriv}
\PYG{c+c1}{\PYGZsh{} 3: sechskant}
\PYG{c+c1}{\PYGZsh{} 4: torx}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Neuronales Netz A (Sechskant)}
\label{\detokenize{02_NN/NeuralNet_1_Keras:neuronales-netz-a-sechskant}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}
\begin{sphinxuseclass}{tag_output_scroll}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sigmoid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{784}\PYG{p}{,}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sigmoid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}sgd = stochastic gradient descent}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sgd}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{binary\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train\PYGZus{}A}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Neuronales Netz B (Pozidriv)}
\label{\detokenize{02_NN/NeuralNet_1_Keras:neuronales-netz-b-pozidriv}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}
\begin{sphinxuseclass}{tag_output_scroll}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sigmoid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{784}\PYG{p}{,}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sigmoid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sgd}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{binary\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train\PYGZus{}B}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{evaluate}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{10500}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{p}{,} \PYG{n}{y\PYGZus{}train}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.evaluate\PYG{o}{?}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{model}\PYG{o}{.}\PYG{n}{metrics\PYGZus{}names}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}

\chapter{NN 2: Mehrere unterscheiden}
\label{\detokenize{02_NN/NeuralNet_2 (Mehrere Ausgaenge):nn-2-mehrere-unterscheiden}}\label{\detokenize{02_NN/NeuralNet_2 (Mehrere Ausgaenge)::doc}}
\sphinxAtStartPar
import os
os.environ{[}“CUDA\_VISIBLE\_DEVICES”{]} = “\sphinxhyphen{}1”

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Vorstellung: MNIST\PYGZhy{}Daten!}
\PYG{c+c1}{\PYGZsh{} http://yann.lecun.com/exdb/mnist/}
\PYG{c+c1}{\PYGZsh{} FashionMNIST: https://github.com/zalandoresearch/fashion\PYGZhy{}mnist}

\PYG{k+kn}{import} \PYG{n+nn}{gzip}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{to\PYGZus{}categorical}

\PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}

\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{1.0}\PYG{o}{/}\PYG{l+m+mf}{255.0}
\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{int32}\PYG{p}{)}

\PYG{n}{X\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{o}{*}\PYG{l+m+mf}{1.0}\PYG{o}{/}\PYG{l+m+mf}{255.0}
\PYG{n}{y\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{int32}\PYG{p}{)}

\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{to\PYGZus{}categorical}\PYG{p}{(}\PYG{n}{y\PYGZus{}train}\PYG{p}{)}
\PYG{n}{y\PYGZus{}test} \PYG{o}{=} \PYG{n}{to\PYGZus{}categorical}\PYG{p}{(}\PYG{n}{y\PYGZus{}test}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZti{}}\PYGZbs{}\PYG{n}{AppData}\PYGZbs{}\PYG{n}{Local}\PYGZbs{}\PYG{n}{Temp}\PYG{o}{/}\PYG{n}{ipykernel\PYGZus{}18584}\PYG{o}{/}\PYG{l+m+mf}{1306288492.}\PYG{n}{py} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{5} \PYG{k+kn}{import} \PYG{n+nn}{gzip}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{6} \PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{7} \PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{to\PYGZus{}categorical}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{8} 
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{9} \PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}tensorflow\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{50}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sigmoid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{784}\PYG{p}{,}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sigmoid}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sgd}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{categorical\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{10500}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{10500}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{80}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{evaluate}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{p}{,} \PYG{n}{y\PYGZus{}test}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Model testen}
\label{\detokenize{02_NN/NeuralNet_2 (Mehrere Ausgaenge):model-testen}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_output_scroll}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline

\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{y\PYGZus{}test}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{plt}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{)}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{gray}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pred} \PYG{o}{=} \PYG{n}{model}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{X\PYGZus{}test}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{784}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{c+c1}{\PYGZsh{} Klasse mit höchster Wahrscheinlichkeit ausgeben:}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
4
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([4, 2, 3, ..., 2, 1, 0])
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Confusion Matrix}
\label{\detokenize{02_NN/NeuralNet_2 (Mehrere Ausgaenge):confusion-matrix}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{n}{ytrue} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{Series}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{y\PYGZus{}test}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{name} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{ytrue}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ypred} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{Series}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{argmax}\PYG{p}{(}\PYG{n}{pred}\PYG{p}{,} \PYG{n}{axis}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{name} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{pred}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{pd}\PYG{o}{.}\PYG{n}{crosstab}\PYG{p}{(}\PYG{n}{ytrue}\PYG{p}{,} \PYG{n}{ypred}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\part{Convolutional Neural Net}


\chapter{Convolutional Neural Networks (CNN)}
\label{\detokenize{03_CNN/CNN:convolutional-neural-networks-cnn}}\label{\detokenize{03_CNN/CNN::doc}}
\sphinxAtStartPar
Ein Theorem aus dem Jahr 1988, das “Universal Approximation Theorem”, sagt, dass jede beliebige, glatte Funktion, durch ein NN mit nur einem Hidden Layer approximiert werden kann. Nach diesem Theorem nach, würde dieses einfache NN bereits in der Lage sein jedes beliebige Bild bzw. die Funktion der Pixelwerte zu erlernen. Die Fehler und die lange Rechenzeit zeigen die Probleme in der Praxis. Denn um dieses Theorem zu erfüllen sind für sehr einfache Netze unendlich viel Rechenleistung, Zeit und Trainingsbeispiele nötig. Diese stehen i.d.R. nicht zur Verfügung. Für die Bilderkennung haben sich CNN’s als sehr wirksam erwiesen. Die Arbeitsweise soll in diesem Abschnitt erläutert werden.
Der Grundgedanke bei der Nutzung der Convolutional Layer ist, dem NN zusätzliches “Spezialwissen” über die Daten zu geben. Das NN ist durch den zusätzlichen Convolutional Layer in der Lage, spezielle Bildelemente und Strukturen besser zu erkennen.

\sphinxAtStartPar
Es werden meist mehrere Convolutional Layer hintereinander geschalten. Das NN kann auf der ersten Ebene lernen, Kanten zu erkennen. Auf weiteren Ebenen lernt es dann weitere “Bild\sphinxhyphen{}Features” wie z.B. Übergänge, Rundungen o.ä. zu erkennen. Diese werden auf höheren Ebenen weiterverarbeitet.

\sphinxAtStartPar
\sphinxstylestrong{Beispiel einer einfachen 1D\sphinxhyphen{}Faltung:}

\sphinxAtStartPar
Die beiden einfachen Beispiele sollen die Berechnung verdeutlichen. Die Filterfunktion wird auf die Pixel gelegt und Elementweise multipliziert.
Im folgenden Beispiel werden 3 Pixel eines Bildes verwendet. Die Ergebnisse sagen etwas über den Bildinhalt aus:
\begin{itemize}
\item {} 
\sphinxAtStartPar
positives Ergebnis: Übergang von hell zu dunkel

\item {} 
\sphinxAtStartPar
negatives Ergebnis: Übergang von dunkel nach hell

\item {} 
\sphinxAtStartPar
neutrales Ergebnis: Übergang wechselnd, hell\sphinxhyphen{}dunkel\sphinxhyphen{}hell  oder dunkel\sphinxhyphen{}hell\sphinxhyphen{}dunkel

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{cnn_1d}.png}
\caption{Eindimensionale Faltung}\label{\detokenize{03_CNN/CNN:markdown-fig}}\end{figure}

\sphinxAtStartPar
Da ein Bild aus mehr als 3 Pixel besteht, muss die Filterfunktion über das gesamte Bild “geschoben” werden. Das folgende Beispiel demonstriert den Vorgang der Convolution im Fall eines eindimensionalen Filter. Der Filter besteht in diesem Fall wieder aus einem Zeilenvektor mit 3 Elementen. Der Filter wird nun Pixelweise über die Bildzeile geschoben, die Ergebnisse werden gespeichert und geben wiederum Aufschluss über die Bildstruktur.
Die Ergebnisse zeigen wieder die enthaltene Bildstruktur:
\begin{itemize}
\item {} 
\sphinxAtStartPar
1: hell\sphinxhyphen{}dunkel

\item {} 
\sphinxAtStartPar
0: hell\sphinxhyphen{}dunkel\sphinxhyphen{}hell

\item {} 
\sphinxAtStartPar
0: dunkel\sphinxhyphen{}hell\sphinxhyphen{}dunkel

\item {} 
\sphinxAtStartPar
1: hell\sphinxhyphen{}dunkel
–1: dunkel\sphinxhyphen{}hell

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{cnn_1d_long}.png}
\caption{Eindimensionale Faltung mit mehreren Übergängen}\label{\detokenize{03_CNN/CNN:id1}}\end{figure}


\section{2\sphinxhyphen{}Dimensionale Faltung}
\label{\detokenize{03_CNN/CNN:dimensionale-faltung}}
\sphinxAtStartPar
In der Praxis werden in der Bilderkennung 2\sphinxhyphen{}dimensionale Filter verwendet, ein häufig verwendetes Format ist ein 3x3 Filter. Der Vorgang ist analog zum eindimensionalen Fall, der Filter wird über das gesamte Bild geschoben. Das folgende Beispiel zeigt einen Filter, der in der Lage ist, senkrechte Kanten zu erkennen.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{cnn_2d_a}.png}
\caption{Eindimensionale Faltung mit mehreren Übergängen}\label{\detokenize{03_CNN/CNN:id2}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{cnn_2d_b}.png}
\caption{Eindimensionale Faltung mit mehreren Übergängen}\label{\detokenize{03_CNN/CNN:id3}}\end{figure}

\sphinxAtStartPar
Die Werte der Filter bilden die Gewichte des Convolutional Layer. Diese Gewichte werden durch das Training selbst bestimmt und somit ist das CNN in der Lage, sich selbstständig auf relevante Features zu fokussieren.

\sphinxAtStartPar
\sphinxstylestrong{Im folgenden noch weitere Ergebnisse für bestimmte Bildstrukturen:}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{cnn_2d_c}.png}
\caption{Eindimensionale Faltung mit mehreren Übergängen}\label{\detokenize{03_CNN/CNN:id4}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=900\sphinxpxdimen]{{cnn_2d_d}.png}
\caption{Eindimensionale Faltung mit mehreren Übergängen}\label{\detokenize{03_CNN/CNN:id5}}\end{figure}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{n}{os}\PYG{o}{.}\PYG{n}{environ}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}1}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Mit Hilfe eines CNN\sphinxhyphen{}Layer bekommt das neuronale Netz ein “Verständnis” für Bilder “eingebaut”. Das NN ist somit auf die Erkennung von Bildern spezialisiert und demensprechend Leistungsfähiger als ein NN ohne dieses Bildverständnis.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Kantenerkennung

\end{itemize}

\sphinxAtStartPar
Das CNN besitzt gegenüber dem neuronalem Netz eine Intuition darüber was ein Bild ist.

\sphinxAtStartPar
Das Neuronale Netz kann auf der ersten Ebene lernen, Kanten zu erkennen. Diese Ebene ist dann für die Kantenerkennung zuständig. Kante ist Kante egal wo auf dem Bild. Diese “Features” werden in den nachfolge Schichten weiterverarbeitet.


\subsection{Beispiel einer einfachen Convolution:}
\label{\detokenize{03_CNN/CNN:beispiel-einer-einfachen-convolution}}
\sphinxAtStartPar
\sphinxurl{https://medium.com/swlh/image-processing-with-python-convolutional-filters-and-kernels-b9884d91a8fd}

\sphinxAtStartPar
Die Filter oder Kernels gibt man nicht vor sondern lässt die Werte vom Convolutional Layer ermitteln. Die Kernels werden dabei so bestimmt dass sie für das Problem am meisten Sinn machen.

\sphinxAtStartPar
Wir möchten nicht nur vertikale Kanten finden, sondern auch schräge und waagerechte. Da jeder Filter für ein bestimmtes Feature zuständig ist, benötigt das CNN mehrere solcher Filter um alle relevanten Zusammenhänge extrahieren zu können. Die Anzahl an Filter die wir bereitstellen hängt von den Daten ab und ist ein Hyperparameter den man tunen muss.


\section{CNN mit Keras}
\label{\detokenize{03_CNN/CNN:cnn-mit-keras}}
\sphinxAtStartPar
Wir wollen nun ein CNN mit Keras entwickeln.

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Vorstellung: MNIST\PYGZhy{}Daten!}
\PYG{c+c1}{\PYGZsh{} http://yann.lecun.com/exdb/mnist/}
\PYG{c+c1}{\PYGZsh{} FashionMNIST: https://github.com/zalandoresearch/fashion\PYGZhy{}mnist}

\PYG{k+kn}{import} \PYG{n+nn}{gzip}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{to\PYGZus{}categorical}


\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../02\PYGZus{}NN/Dataset/X\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{c+c1}{\PYGZsh{}.reshape(\PYGZhy{}1, 784)}
\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../02\PYGZus{}NN/Dataset/y\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{}oh = OneHotEncoder()}
\PYG{c+c1}{\PYGZsh{}y\PYGZus{}train\PYGZus{}oh = oh.fit\PYGZus{}transform(y\PYGZus{}train.reshape(\PYGZhy{}1, 1)).toarray()}

\PYG{n}{X\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../02\PYGZus{}NN/Dataset/X\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{c+c1}{\PYGZsh{}.reshape(\PYGZhy{}1, 784)}
\PYG{n}{y\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{../02\PYGZus{}NN/Dataset/y\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{to\PYGZus{}categorical}\PYG{p}{(}\PYG{n}{y\PYGZus{}train}\PYG{p}{)}
\PYG{n}{y\PYGZus{}test} \PYG{o}{=} \PYG{n}{to\PYGZus{}categorical}\PYG{p}{(}\PYG{n}{y\PYGZus{}test}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{y\PYGZus{}train}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 28, 28)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Das Format der Daten passt noch nicht zum geforderten Eingangsformat.
Das CNN verlangt

\sphinxAtStartPar
Bei einem Wert am Ausgang zwischen 0 und 1 verwendet man “binary crossentropy”. Hat man mehrere Werte / Kategorien am Ausgang, dann verwendet man categorical crossentropy.


\section{stochastic gradient descent}
\label{\detokenize{03_CNN/CNN:stochastic-gradient-descent}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} CNN!}

\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}\PYG{p}{,} \PYG{n}{Conv2D}\PYG{p}{,} \PYG{n}{Flatten}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Conv2D}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{kernel\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}model.add(Conv2D(32, kernel\PYGZus{}size=(3, 3), activation=\PYGZdq{}relu\PYGZdq{}))}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{softmax}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{sgd}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{categorical\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{10500}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{rmsprop}
\label{\detokenize{03_CNN/CNN:rmsprop}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} CNN!}

\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}\PYG{p}{,} \PYG{n}{Conv2D}\PYG{p}{,} \PYG{n}{Flatten}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Conv2D}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{kernel\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{}model.add(Conv2D(32, kernel\PYGZus{}size=(3, 3), activation=\PYGZdq{}relu\PYGZdq{}))}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{softmax}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rmsprop}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{categorical\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{10500}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Two Conv2D Layer}
\label{\detokenize{03_CNN/CNN:two-conv2d-layer}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} CNN!}

\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}\PYG{p}{,} \PYG{n}{Conv2D}\PYG{p}{,} \PYG{n}{Flatten}

\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Conv2D}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{kernel\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Conv2D}\PYG{p}{(}\PYG{l+m+mi}{32}\PYG{p}{,} \PYG{n}{kernel\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{softmax}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rmsprop}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{categorical\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{l+m+mi}{10500}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\chapter{Pooling}
\label{\detokenize{03_CNN/Pooling:pooling}}\label{\detokenize{03_CNN/Pooling::doc}}
\sphinxAtStartPar
Ein Pooling Layer, hat die Aufgabe, das CNN “toleranter” gegen geringe Abweichungen zu machen. Im folgenden Beispiel wurde die Kante stückweise um insgesamt 2 Pixel nach rechts verschoben. Auf einem Bild sollte es für das Erkennen keine so große Rolle spielen aber für den Convolutional\sphinxhyphen{}Layer spielt es eine Rolle in den Ergebnissen. Es ist nicht tolerant gegenüber Verschiebungen.

\sphinxAtStartPar
\sphinxstylestrong{Jede Verschiebung der senkrechten Kante, erzeugt eine andere Featur\sphinxhyphen{}Map:}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{pooling_1}.png}
\caption{Kantenerkennung ohne Pooling.}\label{\detokenize{03_CNN/Pooling:markdown-fig}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=1000\sphinxpxdimen]{{pooling_2}.png}
\caption{Kantenerkennung mit Pooling.}\label{\detokenize{03_CNN/Pooling:id1}}\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Vorteile vom Pooling:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
bessere Generalisierung

\item {} 
\sphinxAtStartPar
geringere Anzahl an Ausgabeknoten durch Dimensionsreduktion

\item {} 
\sphinxAtStartPar
lernen geht schneller

\end{itemize}


\chapter{CNN1}
\label{\detokenize{03_CNN/CNN_1:cnn1}}\label{\detokenize{03_CNN/CNN_1::doc}}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{n}{os}\PYG{o}{.}\PYG{n}{environ}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZhy{}1}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Vorstellung: MNIST\PYGZhy{}Daten!}
\PYG{c+c1}{\PYGZsh{} http://yann.lecun.com/exdb/mnist/}
\PYG{c+c1}{\PYGZsh{} FashionMNIST: https://github.com/zalandoresearch/fashion\PYGZhy{}mnist}

\PYG{k+kn}{import} \PYG{n+nn}{gzip}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{load}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k+kn}{import} \PYG{n}{OneHotEncoder}
\PYG{k+kn}{import} \PYG{n+nn}{tensorflow} \PYG{k}{as} \PYG{n+nn}{tf}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow} \PYG{k+kn}{import} \PYG{n}{keras}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{to\PYGZus{}categorical}

\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{models} \PYG{k+kn}{import} \PYG{n}{Sequential}
\PYG{k+kn}{from} \PYG{n+nn}{tensorflow}\PYG{n+nn}{.}\PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{layers} \PYG{k+kn}{import} \PYG{n}{Dense}\PYG{p}{,} \PYG{n}{Conv2D}\PYG{p}{,} \PYG{n}{Flatten}\PYG{p}{,} \PYG{n}{MaxPooling2D}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{X\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}train.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}

\PYG{n}{X\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/X\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{float32}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{y\PYGZus{}test}\PYG{o}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Dataset/y\PYGZus{}test.npy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{int32}\PYG{p}{)}

\PYG{n}{y\PYGZus{}train} \PYG{o}{=} \PYG{n}{to\PYGZus{}categorical}\PYG{p}{(}\PYG{n}{y\PYGZus{}train}\PYG{p}{)}
\PYG{n}{y\PYGZus{}test} \PYG{o}{=} \PYG{n}{to\PYGZus{}categorical}\PYG{p}{(}\PYG{n}{y\PYGZus{}test}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{X\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{)}
\PYG{n}{y\PYGZus{}train}\PYG{o}{.}\PYG{n}{shape}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 28, 28, 1)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(10500, 5)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{y\PYGZus{}train}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([0., 0., 0., 0., 1.], dtype=float32)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-output}
\begin{sphinxuseclass}{tag_output_scroll}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model} \PYG{o}{=} \PYG{n}{Sequential}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Conv2D}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{n}{kernel\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{relu}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{input\PYGZus{}shape}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{28}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Conv2D}\PYG{p}{(}\PYG{l+m+mi}{32}\PYG{p}{,}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{,}\PYG{n}{activation} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{relu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{MaxPooling2D}\PYG{p}{(}\PYG{n}{pool\PYGZus{}size}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{model}\PYG{o}{.}\PYG{n}{add}\PYG{p}{(}\PYG{n}{Dense}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{activation}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{softmax}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{compile}\PYG{p}{(}\PYG{n}{optimizer}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{rmsprop}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{loss}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{categorical\PYGZus{}crossentropy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{metrics}\PYG{o}{=}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{accuracy}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}
    \PYG{n}{X\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{y\PYGZus{}train}\PYG{p}{,}
    \PYG{n}{epochs}\PYG{o}{=}\PYG{l+m+mi}{15}\PYG{p}{,}
    \PYG{n}{batch\PYGZus{}size}\PYG{o}{=}\PYG{l+m+mi}{500}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxthebibliography}{HdHPK14}
\bibitem[HdHPK14]{00_Intro/intro:id3}
\sphinxAtStartPar
Christopher Ramsay Holdgraf, Wendy de Heer, Brian N. Pasley, and Robert T. Knight. Evidence for Predictive Coding in Human Auditory Cortex. In \sphinxstyleemphasis{International Conference on Cognitive Neuroscience}. Brisbane, Australia, Australia, 2014. Frontiers in Neuroscience.
\end{sphinxthebibliography}







\renewcommand{\indexname}{Index}
\printindex
\end{document}