{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1 (Schraubenk√∂pfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = load('Dataset/X_train.npy').astype(np.float32).reshape(-1, 28,28,1)\n",
    "y_train = load('Dataset/y_train.npy')\n",
    "\n",
    "X_test=load('Dataset/X_test.npy').astype(np.float32).reshape(-1,28,28,1)\n",
    "y_test=load('Dataset/y_test.npy').astype(np.int32)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load('../01_Dataset/dataset_28x28/X_train.npy').astype(np.float32) * 1.0/255.0 # normalisieren\n",
    "y_train=load('../01_Dataset/dataset_28x28/y_train.npy')\n",
    "X_test=load('../01_Dataset/dataset_28x28/X_test.npy').astype(np.float32) * 1.0/255.0  # normalisieren\n",
    "y_test=load('../01_Dataset/dataset_28x28/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6344, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6344, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0.]\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label check\n",
    "i=7\n",
    "print(y_train[i])\n",
    "plt.imshow(X_train[i],cmap='gray')\n",
    "plt.show\n",
    "# 0: innensechskant\n",
    "# 1: philips\n",
    "# 2: pozidriv\n",
    "# 3: sechskant\n",
    "# 4: torx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-output",
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.7060 - accuracy: 0.7065\n",
      "Epoch 2/35\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.3708 - accuracy: 0.8432\n",
      "Epoch 3/35\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.2819 - accuracy: 0.8739\n",
      "Epoch 4/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.2380 - accuracy: 0.8912\n",
      "Epoch 5/35\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.2063 - accuracy: 0.9005\n",
      "Epoch 6/35\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.1751 - accuracy: 0.9213\n",
      "Epoch 7/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1540 - accuracy: 0.9351 \n",
      "Epoch 8/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1303 - accuracy: 0.9480\n",
      "Epoch 9/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.1071 - accuracy: 0.9614\n",
      "Epoch 10/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0831 - accuracy: 0.9718\n",
      "Epoch 11/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0729 - accuracy: 0.9782\n",
      "Epoch 12/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0553 - accuracy: 0.9838\n",
      "Epoch 13/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0408 - accuracy: 0.9910\n",
      "Epoch 14/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0334 - accuracy: 0.9912\n",
      "Epoch 15/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0280 - accuracy: 0.9932\n",
      "Epoch 16/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0180 - accuracy: 0.9965\n",
      "Epoch 17/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0175 - accuracy: 0.9948\n",
      "Epoch 18/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0174 - accuracy: 0.9942\n",
      "Epoch 19/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0137 - accuracy: 0.9953\n",
      "Epoch 20/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0097 - accuracy: 0.9968\n",
      "Epoch 21/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 22/35\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 23/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0071 - accuracy: 0.9983\n",
      "Epoch 24/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0060 - accuracy: 0.9980\n",
      "Epoch 25/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0055 - accuracy: 0.9978\n",
      "Epoch 26/35\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 27/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 28/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0052 - accuracy: 0.9981\n",
      "Epoch 29/35\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.0064 - accuracy: 0.9972\n",
      "Epoch 30/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0039 - accuracy: 0.9984\n",
      "Epoch 31/35\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 32/35\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 33/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0049 - accuracy: 0.9980\n",
      "Epoch 34/35\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 2.3660e-04 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0025 - accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e4dbfab8c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\", input_shape=(28,28,1,)))\n",
    "model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=35,\n",
    "    batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15988/2120964054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=False, validation_split=.1)\n",
    "loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Setup train and test splits\n",
    "(x_train, y_train), (x_test, y_test) = mnist,load_data()\n",
    "print(\"Training label shape: \", y_train,shape) # (60000,) -- 60000 numbers (all 0-9)\n",
    "print(\"First 5 training labels: \", y_train[:5]) # [5, 0, 4, 1, 9]\n",
    "\n",
    "# Convert to \"one-hot\" vectors using the to_categorical function\n",
    "num_classes = 10\n",
    "y_train = keras,utils,to_categorical(y_train, num_classes)\n",
    "y_test = keras,utils,to_categorical(y_test, num_classes)\n",
    "print(\"First 5 training lables as one-hot encoded vectors:\\n\", y_train[:5])\n",
    "\n",
    "# This is the one-hot version of: [5, 0, 4, 1, 9]\n",
    "\"\"\"\n",
    "[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 25,285\n",
      "Trainable params: 25,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense # Dense layers are \"fully connected\" layers\n",
    "from tensorflow.keras.models import Sequential # Documentation: https://keras.io/models/sequential/\n",
    "\n",
    "image_size = 784 # 28*28\n",
    "num_classes = 5 # ten unique digits\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# The input layer requires the special input_shape parameter which should match\n",
    "# the shape of our training data.\n",
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15988/3105391074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train.reshape(-1,784), y_train, batch_size=128, epochs=5, verbose=False, validation_split=.1)\n",
    "loss, accuracy  = model.evaluate(X_test.reshape(-1,784), y_test, verbose=False)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dense(layer_sizes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], activation='sigmoid', input_shape=(image_size,)))\n",
    "\n",
    "    for s in layer_sizes[1:]:\n",
    "        model.add(Dense(units = s, activation = 'sigmoid'))\n",
    "\n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def evaluate(model, batch_size=128, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=False)\n",
    "    loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)\n",
    "    \n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
