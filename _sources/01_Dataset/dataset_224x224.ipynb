{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c13b31-e6cd-4dac-af17-4a54a123d45b",
   "metadata": {},
   "source": [
    "# Datensatz 2 (Schrauben)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd5f7d-e3bc-4581-9929-f8afd6c0ed06",
   "metadata": {},
   "source": [
    "In diesem Abschnitt soll ein Datensatz aus \"echten\" Fotos erstellt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db0f80-e7e4-413d-b4e7-8b48bdefeedc",
   "metadata": {},
   "source": [
    "Wie viele Trainingsdaten benötigt das Netz? Sind [genug Trainingsdaten](https://towardsdatascience.com/how-do-you-know-you-have-enough-training-data-ad9b1fd679ee) vorhanden?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def831b2-ec17-457b-9fa4-79c54293cc7f",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Es stellt sich die Frage wie detailreich die Schraubenbilder sein müssen um eine gute Erkennung zu ermöglichen?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b360d5-0d3c-44d6-bbe2-0723ceb86d95",
   "metadata": {},
   "source": [
    "Um kostengünstig und schnell eine vielzahl an Trainingsbildern von Schrauben zu erzeugen, bieten sich Videoaufnahmen der Schrauben an. Die Videoaufnahmen lassen sich in einzelne Bildern zerlegen und somit ein Datensatz erzeugen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7487b-fac7-4321-9b78-636886d59537",
   "metadata": {},
   "source": [
    "## Extracting and Saving Video Frames using OpenCV-Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc684759-04a9-4893-a37a-b01e146cfb58",
   "metadata": {},
   "source": [
    "```\n",
    "# OpenCV importieren:\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# path = 'relativer Speicherpfad / Dateiname':\n",
    "\n",
    "path = 'pozi/pozi'\n",
    "\n",
    "\n",
    "\n",
    "# Video laden:\n",
    "\n",
    "cap = cv2.VideoCapture('pozi.MOV')\n",
    "i = 0\n",
    "\n",
    "\n",
    "# Prüfen ob ein Video geladen wurde:\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print('ERROR: Datei nicht gefunden')\n",
    "\n",
    "    \n",
    "    \n",
    "# Die Frames des Videos lesen:    \n",
    "    \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "     \n",
    "    # sobald keine Frames mehr gelesen werden können (ret==False) wird abgebrochen:\n",
    "    if ret == False:\n",
    "        break\n",
    "     \n",
    "    # Die Frames speichern\n",
    "    cv2.imwrite(path+str(i)+'.jpg', frame)\n",
    "    i += 1\n",
    " \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855808b-fd39-47e9-9b7d-2178cd9f05ed",
   "metadata": {},
   "source": [
    "### Resize / Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba713e0f-2edd-41fb-98c2-1f98d4385117",
   "metadata": {},
   "outputs": [],
   "source": [
    "```\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('pozi/pozi800.jpg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "print('Original Dimensions : ',img.shape)\n",
    "\n",
    "scale_percent = 50 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "#resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "print('Resized Dimensions : ',resized.shape)\n",
    "\n",
    "cv2.imshow(\"Resized image\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "887970d1-a90f-450d-b086-cb3cd38a77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10800, 224, 224, 3)\n",
      "10800\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "filelist = glob.glob(\"screw_img/**/*\")\n",
    "X_raw = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "print(X_raw.shape)\n",
    "print(len(filelist))\n",
    "\n",
    "# Array erweitern - hier nicht nötig\n",
    "#X_raw = X_raw.reshape(X_raw.shape + (1,))\n",
    "#print(X_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad83667f-db43-458d-b79e-62b805db4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10800, 224, 224)\n",
      "10800\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob(\"screw_img/**/*\")\n",
    "X_gray = np.array([np.array(Image.open(fname).convert('L')) for fname in filelist])\n",
    "print(X_gray.shape)\n",
    "print(len(filelist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264445df-dd2b-4678-9e48-95e5f3255d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array erweitern \n",
    "#X_gray = X_gray.reshape(X_gray.shape + (1,))\n",
    "print(X_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6a8de-5416-459f-9a7a-2dd1c0f26011",
   "metadata": {},
   "source": [
    "### Bilderklassen in separatem Ordner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dde680-04b3-4073-bfcf-0647fba0e768",
   "metadata": {},
   "source": [
    "Die folgende Ordnerstruktur liegt vor:\n",
    "\n",
    "main_directory/  \n",
    "...category_a/  \n",
    "......a_image_1.jpg  \n",
    "......a_image_2.jpg  \n",
    "...category_b/  \n",
    "......b_image_1.jpg  \n",
    "......b_image_2.jpg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab577f3f-7f34-4bda-b3db-0d1c9e3e6030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1801/1801 [00:03<00:00, 577.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1801/1801 [00:03<00:00, 576.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 561.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 521.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 523.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1800/1800 [00:03<00:00, 582.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "IMG_SIZE=224\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do dogs and cats\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=dog 1=cat\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9684ae77-f868-4434-877e-11c37f5de0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[189]\n",
      "   [189]\n",
      "   [191]\n",
      "   ...\n",
      "   [191]\n",
      "   [191]\n",
      "   [196]]\n",
      "\n",
      "  [[188]\n",
      "   [188]\n",
      "   [189]\n",
      "   ...\n",
      "   [192]\n",
      "   [193]\n",
      "   [197]]\n",
      "\n",
      "  [[186]\n",
      "   [185]\n",
      "   [185]\n",
      "   ...\n",
      "   [194]\n",
      "   [190]\n",
      "   [191]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[171]\n",
      "   [175]\n",
      "   [180]\n",
      "   ...\n",
      "   [176]\n",
      "   [174]\n",
      "   [179]]\n",
      "\n",
      "  [[164]\n",
      "   [175]\n",
      "   [183]\n",
      "   ...\n",
      "   [174]\n",
      "   [177]\n",
      "   [182]]\n",
      "\n",
      "  [[168]\n",
      "   [178]\n",
      "   [178]\n",
      "   ...\n",
      "   [171]\n",
      "   [177]\n",
      "   [182]]]]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "751c7fbe-540c-4b8c-b1a9-3e7a549f9ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10800, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10800"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fc2fe-b8d8-4364-8716-cb8d5b8b2fe6",
   "metadata": {},
   "source": [
    "## Datensatz aufteilen in Test- und Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b690982-6fa6-4b83-98f9-991acb4b7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "87687416-e53b-4a14-b37e-89435e9be7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save, load\n",
    "# define data\n",
    "#data = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "# save to npy file\n",
    "save('Dataset_224x224/X_train.npy', X_train)\n",
    "save('Dataset_224x224/y_train.npy', y_train)\n",
    "save('Dataset_224x224/X_test.npy', X_test)\n",
    "save('Dataset_224x224/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c61c01b-1375-4a40-aeea-f91799c0c62b",
   "metadata": {},
   "source": [
    "## Datensatz mit Keras erzeugen und erweitern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b9ece-9f24-4f6e-8ef1-f9a4a77414f1",
   "metadata": {},
   "source": [
    "Mit dem ImageDataGenerator aus dem Keras Paket *Image data preprocessing*, kann ein Datensatz erstellt werden.\n",
    "Der Image Data Generator bietet eine Reihe nützlicher Funktionen um einen Datensatz aus Bildern zu erstellen und zu erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640433cd-381e-4165-a41f-29b318335760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53702f-c229-47a7-8921-982a89b69236",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1fae586c-3dbe-46d8-88aa-81de733a98bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10804 files belonging to 6 classes.\n",
      "(100, 224, 224, 3)\n",
      "<dtype: 'float32'>\n",
      "(100,)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset.\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "  'screw_img', batch_size=100, image_size=(224, 224))\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For demonstration, iterate over the batches yielded by the dataset.\n",
    "for data, labels in dataset:\n",
    "    print(data.shape)  # (64, 200, 200, 3)\n",
    "    print(data.dtype)  # float32\n",
    "    print(labels.shape)  # (64,)\n",
    "    print(labels.dtype)  # int32\n",
    "    break\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5f33667-cdbe-4e3b-bdf8-f7f806261e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = []\n",
    "y_ = []\n",
    "\n",
    "for features,label in dataset:\n",
    "    X_.append(features)\n",
    "    y_.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1f938dfe-afcb-4551-ac41-4dc989361524",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20780/2738484577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(X_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fed77e-2397-4a93-9dc2-15ac9f69a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394aa26-75c2-4b4e-a760-c26e581e254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d92cee-9c87-4c55-8e08-be5d454f60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = X.class_names\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1240f6-6345-436c-8958-b44b50d711bf",
   "metadata": {},
   "source": [
    "## Generator ausprobieren und konfigurieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc4f65-9a3f-4e96-b54e-9e6af18dfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator config:\n",
    "gen = ImageDataGenerator (\n",
    "    #width_shift_range=0,\n",
    "    #height_shift_range=0,\n",
    "    #rotation_range=0,\n",
    "    #shear_range=0.01,\n",
    "    #zoom_range=0.2,\n",
    "    #fill_mode='constant',cval=255 # beste fill mode bei einfarbigen Hintergrund\n",
    ")\n",
    "# generate one image:\n",
    "for batch in gen.flow(\n",
    "    X_raw,\n",
    "    shuffle=False,\n",
    "):\n",
    "    #print(batch.shape)\n",
    "    plt.imshow(batch[0]/255)\n",
    "    plt.show\n",
    "    break\n",
    "    \n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad720a-0a37-4813-b954-281abe554114",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    brightness_range=None,\n",
    "    shear_range=0,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='constant',\n",
    "    cval=255,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=1.0/255.0,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    dtype=None,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "itr = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"grayscale\",\n",
    "    classes=None,\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    save_to_dir='Dataset_vid',\n",
    "    #save_prefix=\"\",\n",
    "    save_format=\"png\",\n",
    "    follow_links=False,\n",
    "    subset=None,\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "    \n",
    "    \n",
    "#target_size=(img_width, img_height),\n",
    "#batch_size=10,\n",
    "#class_mode='categorical')\n",
    "\n",
    "i=0\n",
    "\n",
    "for i in range(0,3):\n",
    "    X, y = itr.next()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045873f5-598d-4da9-b014-bef2c6a0f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save, load\n",
    "# define data\n",
    "#data = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "# save to npy file\n",
    "save('Dataset_vid/X_train.npy', X_train)\n",
    "save('Dataset_vid/y_train.npy', y_train)\n",
    "save('Dataset_vid/X_test.npy', X_test)\n",
    "save('Dataset_vid/y_test.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
